#!/usr/bin/env python3
"""
æµ‹è¯•GPUåŠ é€Ÿ
"""

def test_gpu():
    print("ğŸ§ª æµ‹è¯•GPUåŠ é€Ÿ...")
    
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # æ£€æŸ¥GPU
        if torch.backends.mps.is_available():
            print("âœ… Apple Silicon GPU (MPS) å¯ç”¨")
            device = "mps"
        elif torch.cuda.is_available():
            print("âœ… NVIDIA GPU (CUDA) å¯ç”¨")
            device = "cuda"
        else:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„GPU")
            return
        
        # æµ‹è¯•GPU
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        x = torch.randn(100, 100).to(device)
        y = torch.randn(100, 100).to(device)
        z = torch.mm(x, y)
        print(f"âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸï¼Œç»“æœå½¢çŠ¶: {z.shape}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    test_gpu()
