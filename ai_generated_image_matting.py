#!/usr/bin/env python3
"""
AIç”Ÿæˆå›¾ç‰‡ä¸“ç”¨æŠ å›¾è§£å†³æ–¹æ¡ˆ
ä¸“é—¨è§£å†³å¤æ‚AIç”Ÿæˆå›¾ç‰‡æŠ å›¾æ•ˆæœä¸å¥½çš„é—®é¢˜
"""

import os
import cv2
import numpy as np
from PIL import Image
import time
import io

class AIGeneratedImageMatting:
    """AIç”Ÿæˆå›¾ç‰‡ä¸“ç”¨æŠ å›¾è§£å†³æ–¹æ¡ˆ"""
    
    def __init__(self):
        self.available_methods = self._check_available_methods()
        print("ğŸ¨ AIç”Ÿæˆå›¾ç‰‡ä¸“ç”¨æŠ å›¾å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _check_available_methods(self):
        """æ£€æŸ¥å¯ç”¨æ–¹æ³•"""
        methods = {}
        
        try:
            import rembg
            methods['rembg'] = True
            print("âœ… RemBGå¯ç”¨ - é«˜è´¨é‡AIæŠ å›¾")
        except:
            methods['rembg'] = False
            print("âŒ RemBGä¸å¯ç”¨")
        
        methods['opencv'] = True
        print("âœ… OpenCVå¯ç”¨ - åŸºç¡€å›¾åƒå¤„ç†")
        
        return methods
    
    def process_ai_generated_image(self, image_path, output_path, method='auto'):
        """å¤„ç†AIç”Ÿæˆçš„å›¾ç‰‡"""
        print(f"ğŸ¨ å¼€å§‹å¤„ç†AIç”Ÿæˆå›¾ç‰‡: {os.path.basename(image_path)}")
        
        # åˆ†æAIç”Ÿæˆå›¾ç‰‡çš„ç‰¹å¾
        ai_features = self._analyze_ai_generated_features(image_path)
        print(f"ğŸ“Š AIå›¾ç‰‡ç‰¹å¾åˆ†æ:")
        print(f"  å¤æ‚åº¦è¯„åˆ†: {ai_features['complexity']:.1f}/100")
        print(f"  è‰²å½©ä¸°å¯Œåº¦: {ai_features['color_richness']:.1f}")
        print(f"  è¾¹ç¼˜å¤æ‚åº¦: {ai_features['edge_complexity']:.1f}")
        print(f"  çº¹ç†å¤æ‚åº¦: {ai_features['texture_complexity']:.1f}")
        
        # æ ¹æ®ç‰¹å¾é€‰æ‹©æœ€ä½³æ–¹æ³•
        if method == 'auto':
            method = self._select_best_method_for_ai(ai_features)
        
        print(f"ğŸ¯ é€‰æ‹©æŠ å›¾æ–¹æ³•: {method}")
        
        # æ‰§è¡ŒæŠ å›¾
        result = self._execute_ai_matting(method, image_path, ai_features)
        
        if result is not None:
            # AIä¸“ç”¨åå¤„ç†
            final_result = self._ai_specific_postprocess(result, image_path, ai_features)
            
            # ä¿å­˜ç»“æœ
            if self._save_result(final_result, output_path):
                print(f"âœ… AIç”Ÿæˆå›¾ç‰‡æŠ å›¾å®Œæˆ: {output_path}")
                return output_path
        
        return None
    
    def _analyze_ai_generated_features(self, image_path):
        """åˆ†æAIç”Ÿæˆå›¾ç‰‡çš„ç‰¹å¾"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                return self._default_ai_features()
            
            # è½¬æ¢ä¸ºRGBè¿›è¡Œåˆ†æ
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # 1. å¤æ‚åº¦åˆ†æ
            complexity = self._calculate_complexity(image_rgb, gray)
            
            # 2. è‰²å½©ä¸°å¯Œåº¦
            color_richness = self._calculate_color_richness(image_rgb)
            
            # 3. è¾¹ç¼˜å¤æ‚åº¦
            edge_complexity = self._calculate_edge_complexity(gray)
            
            # 4. çº¹ç†å¤æ‚åº¦
            texture_complexity = self._calculate_texture_complexity(gray)
            
            # 5. AIç”Ÿæˆå›¾ç‰‡ç‰¹å¾æ£€æµ‹
            ai_indicators = self._detect_ai_generation_indicators(image_rgb)
            
            return {
                'complexity': complexity,
                'color_richness': color_richness,
                'edge_complexity': edge_complexity,
                'texture_complexity': texture_complexity,
                'ai_indicators': ai_indicators,
                'image_size': image.shape[:2]
            }
            
        except Exception as e:
            print(f"âš  AIç‰¹å¾åˆ†æå¤±è´¥: {e}")
            return self._default_ai_features()
    
    def _default_ai_features(self):
        """é»˜è®¤AIç‰¹å¾"""
        return {
            'complexity': 50.0,
            'color_richness': 50.0,
            'edge_complexity': 50.0,
            'texture_complexity': 50.0,
            'ai_indicators': {'smoothness': 0.5, 'artifacts': 0.5},
            'image_size': (100, 100)
        }
    
    def _calculate_complexity(self, image_rgb, gray):
        """è®¡ç®—å›¾ç‰‡å¤æ‚åº¦"""
        try:
            # è¾¹ç¼˜å¯†åº¦
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size * 100
            
            # æ‹‰æ™®æ‹‰æ–¯æ–¹å·®
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            laplacian_variance = np.var(laplacian)
            
            # å±€éƒ¨æ–¹å·®
            local_var = cv2.GaussianBlur(gray.astype(np.float32), (15, 15), 3)
            local_variance = np.var(local_var)
            
            # ç»¼åˆå¤æ‚åº¦
            complexity = (
                edge_density * 0.3 +
                min(laplacian_variance / 1000, 30) +
                min(local_variance / 100, 40)
            )
            
            return min(complexity, 100.0)
            
        except Exception as e:
            print(f"âš  å¤æ‚åº¦è®¡ç®—å¤±è´¥: {e}")
            return 50.0
    
    def _calculate_color_richness(self, image_rgb):
        """è®¡ç®—è‰²å½©ä¸°å¯Œåº¦"""
        try:
            # è®¡ç®—æ¯ä¸ªé€šé“çš„æ–¹å·®
            channel_variances = np.var(image_rgb, axis=(0, 1))
            total_variance = np.sum(channel_variances)
            
            # è®¡ç®—è‰²å½©é¥±å’Œåº¦
            hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)
            saturation = hsv[:, :, 1]
            avg_saturation = np.mean(saturation)
            
            # ç»¼åˆè‰²å½©ä¸°å¯Œåº¦
            color_richness = (total_variance / 10000 + avg_saturation / 255) * 50
            
            return min(color_richness, 100.0)
            
        except Exception as e:
            print(f"âš  è‰²å½©ä¸°å¯Œåº¦è®¡ç®—å¤±è´¥: {e}")
            return 50.0
    
    def _calculate_edge_complexity(self, gray):
        """è®¡ç®—è¾¹ç¼˜å¤æ‚åº¦"""
        try:
            # å¤šå°ºåº¦è¾¹ç¼˜æ£€æµ‹
            edges1 = cv2.Canny(gray, 30, 100)
            edges2 = cv2.Canny(gray, 50, 150)
            edges3 = cv2.Canny(gray, 70, 200)
            
            # ç»„åˆè¾¹ç¼˜
            combined_edges = cv2.bitwise_or(edges1, edges2)
            combined_edges = cv2.bitwise_or(combined_edges, edges3)
            
            # è®¡ç®—è¾¹ç¼˜å¯†åº¦å’Œå¤æ‚åº¦
            edge_density = np.sum(combined_edges > 0) / combined_edges.size * 100
            
            # è¾¹ç¼˜å¼ºåº¦
            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
            avg_edge_strength = np.mean(edge_magnitude)
            
            # ç»¼åˆè¾¹ç¼˜å¤æ‚åº¦
            edge_complexity = edge_density * 0.7 + min(avg_edge_strength / 10, 30)
            
            return min(edge_complexity, 100.0)
            
        except Exception as e:
            print(f"âš  è¾¹ç¼˜å¤æ‚åº¦è®¡ç®—å¤±è´¥: {e}")
            return 50.0
    
    def _calculate_texture_complexity(self, gray):
        """è®¡ç®—çº¹ç†å¤æ‚åº¦"""
        try:
            # å±€éƒ¨æ–¹å·®
            local_var = cv2.GaussianBlur(gray.astype(np.float32), (15, 15), 3)
            local_variance = np.var(local_var)
            
            # æ¢¯åº¦æ–¹å·®
            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            gradient_variance = np.var(grad_x) + np.var(grad_y)
            
            # çº¹ç†å¤æ‚åº¦
            texture_complexity = min(local_variance / 100, 50) + min(gradient_variance / 1000, 50)
            
            return texture_complexity
            
        except Exception as e:
            print(f"âš  çº¹ç†å¤æ‚åº¦è®¡ç®—å¤±è´¥: {e}")
            return 50.0
    
    def _detect_ai_generation_indicators(self, image_rgb):
        """æ£€æµ‹AIç”Ÿæˆå›¾ç‰‡çš„æŒ‡æ ‡"""
        try:
            # 1. è‰²å½©è¿‡æ¸¡å¹³æ»‘æ€§ï¼ˆAIç”Ÿæˆçš„å›¾ç‰‡é€šå¸¸æ›´å¹³æ»‘ï¼‰
            diff_x = np.diff(image_rgb, axis=1)
            diff_y = np.diff(image_rgb, axis=0)
            avg_diff_x = np.mean(np.abs(diff_x))
            avg_diff_y = np.mean(np.abs(diff_y))
            
            # å¹³æ»‘åº¦è¯„åˆ†ï¼ˆå·®å¼‚è¶Šå°è¶Šå¹³æ»‘ï¼‰
            smoothness = max(0, 1 - (avg_diff_x + avg_diff_y) / 200)
            
            # 2. æ£€æµ‹å¯èƒ½çš„AIç”Ÿæˆä¼ªå½±
            # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­æ£€æµ‹è¿‡åº¦å¹³æ»‘åŒºåŸŸ
            gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            laplacian_variance = np.var(laplacian)
            
            # ä¼ªå½±æ£€æµ‹ï¼ˆæ–¹å·®è¿‡ä½å¯èƒ½è¡¨ç¤ºè¿‡åº¦å¹³æ»‘ï¼‰
            artifacts = max(0, 1 - laplacian_variance / 10000)
            
            return {
                'smoothness': smoothness,
                'artifacts': artifacts,
                'avg_diff_x': avg_diff_x,
                'avg_diff_y': avg_diff_y,
                'laplacian_variance': laplacian_variance
            }
            
        except Exception as e:
            print(f"âš  AIæŒ‡æ ‡æ£€æµ‹å¤±è´¥: {e}")
            return {'smoothness': 0.5, 'artifacts': 0.5}
    
    def _select_best_method_for_ai(self, ai_features):
        """ä¸ºAIç”Ÿæˆå›¾ç‰‡é€‰æ‹©æœ€ä½³æŠ å›¾æ–¹æ³•"""
        complexity = ai_features['complexity']
        color_richness = ai_features['color_richness']
        edge_complexity = ai_features['edge_complexity']
        ai_indicators = ai_features['ai_indicators']
        
        # å†³ç­–é€»è¾‘
        if complexity > 80:
            # æé«˜å¤æ‚åº¦ï¼šä¼˜å…ˆä½¿ç”¨RemBG
            if self.available_methods.get('rembg'):
                return 'rembg_aggressive'
            else:
                return 'opencv_aggressive'
        
        elif complexity > 60:
            # é«˜å¤æ‚åº¦ï¼šä½¿ç”¨RemBG + ä¿å®ˆå‚æ•°
            if self.available_methods.get('rembg'):
                return 'rembg_conservative'
            else:
                return 'opencv_advanced'
        
        elif complexity > 40:
            # ä¸­ç­‰å¤æ‚åº¦ï¼šå¹³è¡¡æ–¹æ³•
            if self.available_methods.get('rembg'):
                return 'rembg_balanced'
            else:
                return 'opencv_balanced'
        
        else:
            # ä½å¤æ‚åº¦ï¼šç®€å•æ–¹æ³•
            return 'opencv_simple'
    
    def _execute_ai_matting(self, method, image_path, ai_features):
        """æ‰§è¡ŒAIæŠ å›¾"""
        try:
            if method.startswith('rembg'):
                return self._rembg_ai_matting(method, image_path, ai_features)
            elif method.startswith('opencv'):
                return self._opencv_ai_matting(method, image_path, ai_features)
            else:
                print(f"âŒ æœªçŸ¥çš„æŠ å›¾æ–¹æ³•: {method}")
                return None
                
        except Exception as e:
            print(f"âŒ AIæŠ å›¾æ‰§è¡Œå¤±è´¥: {e}")
            return None
    
    def _rembg_ai_matting(self, method, image_path, ai_features):
        """RemBG AIæŠ å›¾"""
        try:
            if not self.available_methods.get('rembg'):
                print("âŒ RemBGä¸å¯ç”¨")
                return None
            
            import rembg
            
            print("ğŸš€ ä½¿ç”¨RemBG AIæŠ å›¾...")
            with open(image_path, 'rb') as f:
                input_data = f.read()
            
            # æ ¹æ®æ–¹æ³•é€‰æ‹©å‚æ•°
            if method == 'rembg_aggressive':
                # æ¿€è¿›å‚æ•°ï¼šé€‚åˆæé«˜å¤æ‚åº¦
                output_data = rembg.remove(input_data, alpha_matting=True, 
                                         alpha_matting_foreground_threshold=250,
                                         alpha_matting_background_threshold=5,
                                         alpha_matting_erode_size=20)
            elif method == 'rembg_conservative':
                # ä¿å®ˆå‚æ•°ï¼šé€‚åˆé«˜å¤æ‚åº¦
                output_data = rembg.remove(input_data, alpha_matting=True, 
                                         alpha_matting_foreground_threshold=240,
                                         alpha_matting_background_threshold=10,
                                         alpha_matting_erode_size=15)
            else:
                # å¹³è¡¡å‚æ•°ï¼šé»˜è®¤
                output_data = rembg.remove(input_data, alpha_matting=True, 
                                         alpha_matting_foreground_threshold=235,
                                         alpha_matting_background_threshold=15,
                                         alpha_matting_erode_size=10)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            output_image = Image.open(io.BytesIO(output_data))
            result = np.array(output_image)
            
            return result
            
        except Exception as e:
            print(f"âŒ RemBG AIæŠ å›¾å¤±è´¥: {e}")
            return None
    
    def _opencv_ai_matting(self, method, image_path, ai_features):
        """OpenCV AIæŠ å›¾"""
        try:
            print(f"ğŸ”§ ä½¿ç”¨OpenCV AIæŠ å›¾: {method}")
            
            image = cv2.imread(image_path)
            if image is None:
                return None
            
            # æ ¹æ®æ–¹æ³•é€‰æ‹©ç­–ç•¥
            if method == 'opencv_aggressive':
                # æ¿€è¿›ç­–ç•¥ï¼šé€‚åˆæé«˜å¤æ‚åº¦
                mask = self._create_aggressive_opencv_mask(image, ai_features)
            elif method == 'opencv_advanced':
                # é«˜çº§ç­–ç•¥ï¼šé€‚åˆé«˜å¤æ‚åº¦
                mask = self._create_advanced_opencv_mask(image, ai_features)
            elif method == 'opencv_balanced':
                # å¹³è¡¡ç­–ç•¥ï¼šé€‚åˆä¸­ç­‰å¤æ‚åº¦
                mask = self._create_balanced_opencv_mask(image, ai_features)
            else:
                # ç®€å•ç­–ç•¥ï¼šé€‚åˆä½å¤æ‚åº¦
                mask = self._create_simple_opencv_mask(image, ai_features)
            
            # åº”ç”¨æ©ç 
            result = self._apply_mask_to_image(image, mask)
            
            return result
            
        except Exception as e:
            print(f"âŒ OpenCV AIæŠ å›¾å¤±è´¥: {e}")
            return None
    
    def _create_aggressive_opencv_mask(self, image, ai_features):
        """åˆ›å»ºæ¿€è¿›çš„OpenCVæ©ç """
        try:
            # å¤šç­–ç•¥ç»„åˆ
            masks = []
            
            # 1. è‡ªé€‚åº”é¢œè‰²é˜ˆå€¼
            color_mask = self._create_ai_adaptive_color_mask(image, ai_features, sensitivity=0.9)
            if color_mask is not None:
                masks.append(color_mask)
            
            # 2. å¤šå°ºåº¦è¾¹ç¼˜æ£€æµ‹
            edge_mask = self._create_ai_edge_mask(image, ai_features, scale_factor=1.5)
            if edge_mask is not None:
                masks.append(edge_mask)
            
            # 3. çº¹ç†åˆ†æ
            texture_mask = self._create_ai_texture_mask(image, ai_features, sensitivity=0.8)
            if texture_mask is not None:
                masks.append(texture_mask)
            
            # 4. åŒºåŸŸç”Ÿé•¿
            region_mask = self._create_ai_region_growing_mask(image, ai_features, seed_points=10)
            if region_mask is not None:
                masks.append(region_mask)
            
            # æ™ºèƒ½ç»„åˆ
            if masks:
                final_mask = self._intelligent_ai_mask_combination(masks, ai_features)
            else:
                final_mask = self._create_fallback_mask(image)
            
            return final_mask
            
        except Exception as e:
            print(f"âš  æ¿€è¿›æ©ç åˆ›å»ºå¤±è´¥: {e}")
            return self._create_fallback_mask(image)
    
    def _create_ai_adaptive_color_mask(self, image, ai_features, sensitivity=0.8):
        """åˆ›å»ºAIè‡ªé€‚åº”çš„é¢œè‰²æ©ç """
        try:
            # è½¬æ¢ä¸ºHSV
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´å‚æ•°
            complexity = ai_features['complexity']
            color_richness = ai_features['color_richness']
            
            # åŠ¨æ€è°ƒæ•´æ•æ„Ÿåº¦
            if complexity > 70:
                sensitivity *= 1.2  # é«˜å¤æ‚åº¦å¢åŠ æ•æ„Ÿåº¦
            if color_richness > 70:
                sensitivity *= 0.9  # é«˜è‰²å½©ä¸°å¯Œåº¦é™ä½æ•æ„Ÿåº¦
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            h_mean, s_mean, v_mean = np.mean(hsv, axis=(0, 1))
            h_std, s_std, v_std = np.std(hsv, axis=(0, 1))
            
            # è‡ªé€‚åº”é˜ˆå€¼
            h_lower = max(0, int(h_mean - h_std * sensitivity))
            h_upper = min(179, int(h_mean + h_std * sensitivity))
            s_lower = max(0, int(s_mean - s_std * sensitivity))
            s_upper = min(255, int(s_mean + s_std * sensitivity))
            v_lower = max(0, int(v_mean - v_std * sensitivity))
            v_upper = min(255, int(v_mean + v_std * sensitivity))
            
            # åˆ›å»ºæ©ç 
            lower_bound = np.array([h_lower, s_lower, v_lower], dtype=np.uint8)
            upper_bound = np.array([h_upper, s_upper, v_upper], dtype=np.uint8)
            
            mask = cv2.inRange(hsv, lower_bound, upper_bound)
            
            return mask
            
        except Exception as e:
            print(f"âš  AIè‡ªé€‚åº”é¢œè‰²æ©ç å¤±è´¥: {e}")
            return None
    
    def _create_ai_edge_mask(self, image, ai_features, scale_factor=1.0):
        """åˆ›å»ºAIè‡ªé€‚åº”çš„è¾¹ç¼˜æ©ç """
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´å‚æ•°
            edge_complexity = ai_features['edge_complexity']
            
            # åŠ¨æ€è°ƒæ•´è¾¹ç¼˜æ£€æµ‹å‚æ•°
            if edge_complexity > 70:
                # é«˜è¾¹ç¼˜å¤æ‚åº¦ï¼šä½¿ç”¨æ›´å¤šå°ºåº¦
                edges1 = cv2.Canny(gray, 20, 80)
                edges2 = cv2.Canny(gray, 40, 120)
                edges3 = cv2.Canny(gray, 60, 160)
                edges4 = cv2.Canny(gray, 80, 200)
                
                combined = cv2.bitwise_or(edges1, edges2)
                combined = cv2.bitwise_or(combined, edges3)
                combined = cv2.bitwise_or(combined, edges4)
            else:
                # æ ‡å‡†å¤šå°ºåº¦
                edges1 = cv2.Canny(gray, 30, 100)
                edges2 = cv2.Canny(gray, 50, 150)
                edges3 = cv2.Canny(gray, 70, 200)
                
                combined = cv2.bitwise_or(edges1, edges2)
                combined = cv2.bitwise_or(combined, edges3)
            
            # è†¨èƒ€å’Œå¡«å……
            kernel_size = max(3, int(5 * scale_factor))
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            dilated = cv2.dilate(combined, kernel, iterations=2)
            
            # å¡«å……è½®å»“
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            mask = np.zeros_like(gray)
            if contours:
                cv2.fillPoly(mask, contours, 255)
            
            return mask
            
        except Exception as e:
            print(f"âš  AIè¾¹ç¼˜æ©ç å¤±è´¥: {e}")
            return None
    
    def _create_ai_texture_mask(self, image, ai_features, sensitivity=0.7):
        """åˆ›å»ºAIè‡ªé€‚åº”çš„çº¹ç†æ©ç """
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´å‚æ•°
            texture_complexity = ai_features['texture_complexity']
            
            # åŠ¨æ€è°ƒæ•´çº¹ç†æ£€æµ‹
            if texture_complexity > 70:
                # é«˜çº¹ç†å¤æ‚åº¦ï¼šä½¿ç”¨æ›´ç²¾ç»†çš„åˆ†æ
                kernel_size = 11
                blur_sigma = 2
            else:
                # æ ‡å‡†å‚æ•°
                kernel_size = 15
                blur_sigma = 3
            
            # è®¡ç®—å±€éƒ¨æ–¹å·®
            local_var = cv2.GaussianBlur(gray.astype(np.float32), (kernel_size, kernel_size), blur_sigma)
            local_variance = np.var(local_var)
            
            # åˆ›å»ºçº¹ç†æ©ç 
            texture_threshold = local_variance * sensitivity
            texture_mask = (local_variance > texture_threshold).astype(np.uint8) * 255
            
            return texture_mask
            
        except Exception as e:
            print(f"âš  AIçº¹ç†æ©ç å¤±è´¥: {e}")
            return None
    
    def _create_ai_region_growing_mask(self, image, ai_features, seed_points=5):
        """åˆ›å»ºAIè‡ªé€‚åº”çš„åŒºåŸŸç”Ÿé•¿æ©ç """
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´å‚æ•°
            complexity = ai_features['complexity']
            
            # åŠ¨æ€è°ƒæ•´åŒºåŸŸç”Ÿé•¿å‚æ•°
            if complexity > 70:
                threshold = 15  # é«˜å¤æ‚åº¦ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼
                seed_points = max(seed_points, 15)
            else:
                threshold = 25  # ä½å¤æ‚åº¦ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼
                seed_points = max(seed_points, 5)
            
            # é€‰æ‹©ç§å­ç‚¹
            height, width = gray.shape
            seeds = []
            for _ in range(seed_points):
                x = np.random.randint(width // 4, 3 * width // 4)
                y = np.random.randint(height // 4, 3 * height // 4)
                seeds.append((x, y))
            
            # åŒºåŸŸç”Ÿé•¿
            mask = np.zeros_like(gray)
            for seed_x, seed_y in seeds:
                region = self._grow_ai_region(gray, seed_x, seed_y, threshold)
                mask = cv2.bitwise_or(mask, region)
            
            return mask
            
        except Exception as e:
            print(f"âš  AIåŒºåŸŸç”Ÿé•¿æ©ç å¤±è´¥: {e}")
            return None
    
    def _grow_ai_region(self, gray, start_x, start_y, threshold):
        """AIåŒºåŸŸç”Ÿé•¿ç®—æ³•"""
        try:
            height, width = gray.shape
            mask = np.zeros_like(gray)
            
            # ç§å­ç‚¹
            seed_value = gray[start_y, start_x]
            stack = [(start_x, start_y)]
            mask[start_y, start_x] = 255
            
            # 8é‚»åŸŸ
            neighbors = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]
            
            while stack:
                x, y = stack.pop()
                
                for dx, dy in neighbors:
                    nx, ny = x + dx, y + dy
                    
                    if (0 <= nx < width and 0 <= ny < height and 
                        mask[ny, nx] == 0 and 
                        abs(int(gray[ny, nx]) - int(seed_value)) <= threshold):
                        
                        mask[ny, nx] = 255
                        stack.append((nx, ny))
            
            return mask
            
        except Exception as e:
            return np.zeros_like(gray)
    
    def _intelligent_ai_mask_combination(self, masks, ai_features):
        """æ™ºèƒ½AIæ©ç ç»„åˆ"""
        try:
            if not masks:
                return np.ones((100, 100), dtype=np.uint8) * 255
            
            # è¿‡æ»¤æœ‰æ•ˆæ©ç 
            valid_masks = [m for m in masks if m is not None]
            if not valid_masks:
                return np.ones((100, 100), dtype=np.uint8) * 255
            
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´æƒé‡
            complexity = ai_features['complexity']
            
            if complexity > 70:
                # é«˜å¤æ‚åº¦ï¼šé¢œè‰²æ©ç æƒé‡æ›´é«˜
                weights = [0.5, 0.3, 0.15, 0.05]
            elif complexity > 50:
                # ä¸­ç­‰å¤æ‚åº¦ï¼šå¹³è¡¡æƒé‡
                weights = [0.4, 0.3, 0.2, 0.1]
            else:
                # ä½å¤æ‚åº¦ï¼šè¾¹ç¼˜æ©ç æƒé‡æ›´é«˜
                weights = [0.3, 0.4, 0.2, 0.1]
            
            # ç¡®ä¿æƒé‡æ•°é‡åŒ¹é…
            weights = weights[:len(valid_masks)]
            weights = np.array(weights)
            weights = weights / np.sum(weights)
            
            # åŠ æƒç»„åˆ
            combined_mask = np.zeros_like(valid_masks[0], dtype=np.float32)
            for mask, weight in zip(valid_masks, weights):
                combined_mask += mask.astype(np.float32) * weight
            
            # è½¬æ¢ä¸ºäºŒå€¼æ©ç 
            final_mask = (combined_mask > 127).astype(np.uint8) * 255
            
            return final_mask
            
        except Exception as e:
            print(f"âš  AIæ©ç ç»„åˆå¤±è´¥: {e}")
            return masks[0] if masks and masks[0] is not None else np.ones((100, 100), dtype=np.uint8) * 255
    
    def _create_fallback_mask(self, image):
        """åˆ›å»ºå›é€€æ©ç """
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ä½¿ç”¨Otsuè‡ªé€‚åº”é˜ˆå€¼
            _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            return mask
            
        except Exception as e:
            print(f"âš  å›é€€æ©ç å¤±è´¥: {e}")
            return np.ones(image.shape[:2], dtype=np.uint8) * 255
    
    def _apply_mask_to_image(self, image, mask):
        """å°†æ©ç åº”ç”¨åˆ°å›¾ç‰‡"""
        try:
            # ç¡®ä¿æ©ç æœ‰æ•ˆ
            if mask is None:
                print("âš  æ©ç æ— æ•ˆï¼Œä½¿ç”¨å…¨å‰æ™¯")
                mask = np.ones(image.shape[:2], dtype=np.uint8) * 255
            
            # ç¡®ä¿å°ºå¯¸ä¸€è‡´
            if mask.shape != image.shape[:2]:
                mask = cv2.resize(mask, (image.shape[1], image.shape[0]))
            
            # åˆ›å»ºRGBAç»“æœ
            result = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)
            result[:, :, :3] = image
            result[:, :, 3] = mask
            
            return result
            
        except Exception as e:
            print(f"âš  æ©ç åº”ç”¨å¤±è´¥: {e}")
            return image
    
    def _ai_specific_postprocess(self, result, original_path, ai_features):
        """AIä¸“ç”¨åå¤„ç†"""
        try:
            print("ğŸ”§ å¼€å§‹AIä¸“ç”¨åå¤„ç†...")
            
            if len(result.shape) != 3 or result.shape[2] != 4:
                return result
            
            alpha = result[:, :, 3]
            
            # 1. AIç‰¹å¾æ„ŸçŸ¥çš„å‰æ™¯æ‰©å±•
            foreground_ratio = np.sum(alpha > 128) / alpha.size * 100
            if foreground_ratio < 30:
                print(f"âš  æ£€æµ‹åˆ°è¿‡åº¦æŠ å›¾ï¼ˆå‰æ™¯åŒºåŸŸ: {foreground_ratio:.1f}%ï¼‰ï¼Œå¼€å§‹AIæ™ºèƒ½æ‰©å±•...")
                alpha = self._ai_smart_foreground_expansion(alpha, ai_features)
                result[:, :, 3] = alpha
                new_ratio = np.sum(alpha > 128) / alpha.size * 100
                print(f"âœ… AIæ™ºèƒ½æ‰©å±•å®Œæˆï¼Œæ–°å‰æ™¯åŒºåŸŸ: {new_ratio:.1f}%")
            
            # 2. AIæ„ŸçŸ¥çš„è¾¹ç¼˜ä¼˜åŒ–
            alpha = self._ai_edge_optimization(alpha, ai_features)
            result[:, :, 3] = alpha
            
            # 3. AIè‰²å½©å¢å¼º
            result = self._ai_color_enhancement(result, ai_features)
            
            # 4. AIç»†èŠ‚æ¢å¤
            if ai_features['complexity'] > 60:
                result = self._ai_detail_restoration(result, original_path, ai_features)
            
            print("âœ… AIä¸“ç”¨åå¤„ç†å®Œæˆ")
            return result
            
        except Exception as e:
            print(f"âš  AIåå¤„ç†å¤±è´¥: {e}")
            return result
    
    def _ai_smart_foreground_expansion(self, alpha, ai_features):
        """AIæ™ºèƒ½å‰æ™¯æ‰©å±•"""
        try:
            # å‰æ™¯æ©ç 
            foreground = alpha > 128
            
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´æ‰©å±•å‚æ•°
            complexity = ai_features['complexity']
            
            if complexity > 70:
                # é«˜å¤æ‚åº¦ï¼šæ›´æ¿€è¿›çš„æ‰©å±•
                kernel_size = 9
                iterations = 3
                blur_sigma = 4
            elif complexity > 50:
                # ä¸­ç­‰å¤æ‚åº¦ï¼šå¹³è¡¡æ‰©å±•
                kernel_size = 7
                iterations = 2
                blur_sigma = 3
            else:
                # ä½å¤æ‚åº¦ï¼šä¿å®ˆæ‰©å±•
                kernel_size = 5
                iterations = 1
                blur_sigma = 2
            
            # å½¢æ€å­¦è†¨èƒ€
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            expanded = cv2.dilate(foreground.astype(np.uint8), kernel, iterations=iterations)
            
            # é«˜æ–¯æ¨¡ç³Šåˆ›å»ºå¹³æ»‘è¿‡æ¸¡
            expanded = cv2.GaussianBlur(expanded.astype(np.float32), (15, 15), blur_sigma)
            
            # é‡æ–°æ˜ å°„åˆ°0-255
            expanded_alpha = (expanded * 255).astype(np.uint8)
            
            return expanded_alpha
            
        except Exception as e:
            print(f"âš  AIæ™ºèƒ½å‰æ™¯æ‰©å±•å¤±è´¥: {e}")
            return alpha
    
    def _ai_edge_optimization(self, alpha, ai_features):
        """AIæ„ŸçŸ¥çš„è¾¹ç¼˜ä¼˜åŒ–"""
        try:
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´è¾¹ç¼˜ä¼˜åŒ–å‚æ•°
            edge_complexity = ai_features['edge_complexity']
            
            if edge_complexity > 70:
                # é«˜è¾¹ç¼˜å¤æ‚åº¦ï¼šæ›´ç²¾ç»†çš„ä¼˜åŒ–
                bilateral_d = 9
                bilateral_sigma_color = 75
                bilateral_sigma_space = 75
                gaussian_kernel = 3
                gaussian_sigma = 0.5
            else:
                # æ ‡å‡†å‚æ•°
                bilateral_d = 9
                bilateral_sigma_color = 75
                bilateral_sigma_space = 75
                gaussian_kernel = 3
                gaussian_sigma = 0.5
            
            # åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜
            optimized = cv2.bilateralFilter(alpha, bilateral_d, bilateral_sigma_color, bilateral_sigma_space)
            
            # è½»å¾®é«˜æ–¯æ¨¡ç³Š
            optimized = cv2.GaussianBlur(optimized.astype(np.float32), (gaussian_kernel, gaussian_kernel), gaussian_sigma)
            
            return optimized.astype(np.uint8)
            
        except Exception as e:
            print(f"âš  AIè¾¹ç¼˜ä¼˜åŒ–å¤±è´¥: {e}")
            return alpha
    
    def _ai_color_enhancement(self, result, ai_features):
        """AIè‰²å½©å¢å¼º"""
        try:
            # æ ¹æ®AIç‰¹å¾è°ƒæ•´è‰²å½©å¢å¼ºå‚æ•°
            color_richness = ai_features['color_richness']
            ai_indicators = ai_features['ai_indicators']
            
            # åŠ¨æ€è°ƒæ•´å¢å¼ºå¼ºåº¦
            if color_richness > 70:
                saturation_factor = 1.3  # é«˜è‰²å½©ä¸°å¯Œåº¦ï¼šæ›´å¼ºå¢å¼º
                brightness_factor = 1.15
            elif color_richness > 50:
                saturation_factor = 1.2  # ä¸­ç­‰è‰²å½©ä¸°å¯Œåº¦ï¼šæ ‡å‡†å¢å¼º
                brightness_factor = 1.1
            else:
                saturation_factor = 1.1  # ä½è‰²å½©ä¸°å¯Œåº¦ï¼šè½»å¾®å¢å¼º
                brightness_factor = 1.05
            
            # æ ¹æ®AIç”ŸæˆæŒ‡æ ‡è°ƒæ•´
            if ai_indicators['smoothness'] > 0.7:
                # AIç”Ÿæˆçš„å›¾ç‰‡é€šå¸¸æ›´å¹³æ»‘ï¼Œå¯ä»¥æ›´å¼ºå¢å¼º
                saturation_factor *= 1.1
                brightness_factor *= 1.05
            
            # åªå¤„ç†RGBé€šé“
            rgb = result[:, :, :3].astype(np.float32)
            
            # è½¬æ¢ä¸ºHSV
            hsv = cv2.cvtColor(rgb.astype(np.uint8), cv2.COLOR_RGB2HSV).astype(np.float32)
            
            # å¢å¼ºé¥±å’Œåº¦
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * saturation_factor, 0, 255)
            
            # å¢å¼ºäº®åº¦
            hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)
            
            # è½¬æ¢å›RGB
            enhanced_rgb = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
            
            result[:, :, :3] = enhanced_rgb
            
            return result
            
        except Exception as e:
            print(f"âš  AIè‰²å½©å¢å¼ºå¤±è´¥: {e}")
            return result
    
    def _ai_detail_restoration(self, result, original_path, ai_features):
        """AIç»†èŠ‚æ¢å¤"""
        try:
            # è¯»å–åŸå§‹å›¾ç‰‡
            original = cv2.imread(original_path)
            if original is None:
                return result
            
            # è½¬æ¢ä¸ºRGB
            original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
            
            # åˆ›å»ºç»†èŠ‚æ©ç ï¼ˆå®Œå…¨ä¸é€æ˜åŒºåŸŸï¼‰
            alpha = result[:, :, 3]
            detail_mask = (alpha > 200).astype(np.float32)
            
            # åœ¨å®Œå…¨ä¸é€æ˜åŒºåŸŸæ¢å¤åŸå§‹ç»†èŠ‚
            for i in range(3):
                result[:, :, i] = (result[:, :, i] * (1 - detail_mask) + 
                                  original_rgb[:, :, i] * detail_mask).astype(np.uint8)
            
            return result
            
        except Exception as e:
            print(f"âš  AIç»†èŠ‚æ¢å¤å¤±è´¥: {e}")
            return result
    
    def _save_result(self, result, output_path):
        """ä¿å­˜ç»“æœ"""
        try:
            # è½¬æ¢ä¸ºPIL Image
            if len(result.shape) == 3 and result.shape[2] == 4:
                image = Image.fromarray(result, 'RGBA')
            else:
                image = Image.fromarray(result)
            
            # ä¿å­˜
            image.save(output_path, 'PNG')
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AIç”Ÿæˆå›¾ç‰‡ä¸“ç”¨æŠ å›¾è§£å†³æ–¹æ¡ˆ")
    print("ä¸“é—¨è§£å†³å¤æ‚AIç”Ÿæˆå›¾ç‰‡æŠ å›¾æ•ˆæœä¸å¥½çš„é—®é¢˜")
    print("=" * 60)
    
    # åˆ›å»ºAIæŠ å›¾å™¨
    matting = AIGeneratedImageMatting()
    
    # æµ‹è¯•å›¾ç‰‡
    test_images = [
        "./images/bomb.png",
        "./images/resume_pressed.png"
    ]
    
    # è¿‡æ»¤å­˜åœ¨çš„å›¾ç‰‡
    existing_images = [img for img in test_images if os.path.exists(img)]
    
    if not existing_images:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return
    
    print(f"ğŸ“¸ æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡: {len(existing_images)} å¼ ")
    
    # æµ‹è¯•æ¯å¼ å›¾ç‰‡
    for i, test_image in enumerate(existing_images):
        print(f"\nğŸ­ æµ‹è¯•å›¾ç‰‡ {i+1}: {os.path.basename(test_image)}")
        print("-" * 60)
        
        output_path = f"ai_matting_{i+1}_{os.path.basename(test_image)}"
        
        try:
            # ä½¿ç”¨AIä¸“ç”¨æŠ å›¾
            result = matting.process_ai_generated_image(test_image, output_path)
            
            if result:
                print(f"âœ… AIç”Ÿæˆå›¾ç‰‡æŠ å›¾æˆåŠŸ: {output_path}")
                
                # æ¸…ç†æ¼”ç¤ºæ–‡ä»¶
                try:
                    os.remove(output_path)
                    print("âœ“ æ¼”ç¤ºæ–‡ä»¶å·²æ¸…ç†")
                except:
                    pass
            else:
                print("âŒ AIç”Ÿæˆå›¾ç‰‡æŠ å›¾å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ AIç”Ÿæˆå›¾ç‰‡ä¸“ç”¨æŠ å›¾æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä¸»è¦ç‰¹æ€§:")
    print("â€¢ AIç‰¹å¾æ™ºèƒ½åˆ†æ")
    print("â€¢ å¤æ‚åº¦è‡ªé€‚åº”å‚æ•°è°ƒæ•´")
    print("â€¢ å¤šç­–ç•¥æ™ºèƒ½æ©ç åˆ›å»º")
    print("â€¢ AIä¸“ç”¨åå¤„ç†ä¼˜åŒ–")
    print("â€¢ æ™ºèƒ½å‰æ™¯æ‰©å±•å’Œè¾¹ç¼˜ä¼˜åŒ–")
    print("â€¢ AIè‰²å½©å¢å¼ºå’Œç»†èŠ‚æ¢å¤")
    print("\nğŸ¯ ç°åœ¨åº”è¯¥èƒ½æ›´å¥½åœ°å¤„ç†å¤æ‚çš„AIç”Ÿæˆå›¾ç‰‡ï¼")
    print("=" * 60)

if __name__ == "__main__":
    main()
