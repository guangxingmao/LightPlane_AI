#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºæœºå™¨å­¦ä¹ çš„æ¸¸æˆAIæ§åˆ¶å™¨
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from collections import deque
import random
import pickle
import os
from typing import Dict, List, Tuple, Any

class GameStateEncoder(nn.Module):
    """æ¸¸æˆçŠ¶æ€ç¼–ç å™¨ - å°†æ¸¸æˆçŠ¶æ€è½¬æ¢ä¸ºç¥ç»ç½‘ç»œè¾“å…¥"""
    
    def __init__(self, input_size=50, hidden_size=128, encoded_size=32):
        super(GameStateEncoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Linear(hidden_size // 2, encoded_size),
            nn.Tanh()
        )
    
    def forward(self, x):
        return self.encoder(x)

class GamePatternGenerator(nn.Module):
    """æ¸¸æˆæ¨¡å¼ç”Ÿæˆå™¨ - æ ¹æ®ç¼–ç çš„æ¸¸æˆçŠ¶æ€ç”Ÿæˆæ¸¸æˆå‚æ•°"""
    
    def __init__(self, input_size=50, hidden_size=64, output_size=20):
        super(GamePatternGenerator, self).__init__()
        self.generator = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size),
            nn.Sigmoid()  # è¾“å‡º0-1ä¹‹é—´çš„å€¼
        )
    
    def forward(self, x):
        # ç¡®ä¿è¾“å…¥ç»´åº¦æ­£ç¡®
        if x.dim() == 1:
            x = x.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        return self.generator(x)

class MLGameAI:
    """åŸºäºæœºå™¨å­¦ä¹ çš„æ¸¸æˆAIæ§åˆ¶å™¨"""
    
    def __init__(self, model_path=None):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ¤– MLæ¸¸æˆAIä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # ç¥ç»ç½‘ç»œæ¨¡å‹
        self.state_encoder = GameStateEncoder().to(self.device)
        self.pattern_generator = GamePatternGenerator().to(self.device)
        
        # ä¼˜åŒ–å™¨
        self.encoder_optimizer = optim.Adam(self.state_encoder.parameters(), lr=0.001)
        self.generator_optimizer = optim.Adam(self.pattern_generator.parameters(), lr=0.001)
        
        # æŸå¤±å‡½æ•°
        self.encoder_criterion = nn.MSELoss()
        self.generator_criterion = nn.MSELoss()
        
        # ç»éªŒå›æ”¾ç¼“å†²åŒº
        self.experience_buffer = deque(maxlen=10000)
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)
            print(f"âœ… å·²åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
    
    def encode_game_state(self, game_state: Dict[str, Any]) -> torch.Tensor:
        """å°†æ¸¸æˆçŠ¶æ€ç¼–ç ä¸ºç¥ç»ç½‘ç»œè¾“å…¥"""
        # æå–å…³é”®ç‰¹å¾
        features = []
        
        # ç©å®¶çŠ¶æ€
        features.extend([
            game_state.get('player_health', 100) / 100.0,  # å½’ä¸€åŒ–ç”Ÿå‘½å€¼
            game_state.get('player_score', 0) / 1000.0,    # å½’ä¸€åŒ–åˆ†æ•°
            game_state.get('enemies_killed', 0) / 50.0,    # å½’ä¸€åŒ–å‡»æ€æ•°
            game_state.get('survival_time', 0) / 300.0,    # å½’ä¸€åŒ–ç”Ÿå­˜æ—¶é—´
        ])
        
        # æ•ŒæœºçŠ¶æ€
        features.extend([
            len(game_state.get('enemies', [])) / 20.0,     # å½’ä¸€åŒ–æ•Œæœºæ•°é‡
            game_state.get('average_enemy_speed', 5) / 10.0,  # å½’ä¸€åŒ–æ•Œæœºé€Ÿåº¦
            game_state.get('enemy_density', 0) / 1.0,      # æ•Œæœºå¯†åº¦
        ])
        
        # é“å…·çŠ¶æ€
        features.extend([
            len(game_state.get('power_ups', [])) / 10.0,   # å½’ä¸€åŒ–é“å…·æ•°é‡
            game_state.get('power_up_collection_rate', 0), # é“å…·æ”¶é›†ç‡
        ])
        
        # æ¸¸æˆéš¾åº¦
        features.extend([
            game_state.get('ai_difficulty', 1.0) / 2.0,   # å½’ä¸€åŒ–éš¾åº¦
            game_state.get('player_performance', 0.5),     # ç©å®¶è¡¨ç°
        ])
        
        # å¡«å……åˆ°å›ºå®šé•¿åº¦
        while len(features) < 50:
            features.append(0.0)
        
        return torch.FloatTensor(features[:50]).to(self.device)
    
    def generate_game_pattern(self, game_state: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®æ¸¸æˆçŠ¶æ€ç”Ÿæˆæ¸¸æˆæ¨¡å¼"""
        # ç¼–ç æ¸¸æˆçŠ¶æ€
        encoded_state = self.encode_game_state(game_state)
        
        # ç”Ÿæˆæ¸¸æˆå‚æ•°
        with torch.no_grad():
            # ç¡®ä¿è¾“å…¥ç»´åº¦æ­£ç¡®
            if encoded_state.dim() == 1:
                encoded_state = encoded_state.unsqueeze(0)
            # ç›´æ¥ä½¿ç”¨ç¼–ç åçš„çŠ¶æ€ï¼Œä¸ç»è¿‡çŠ¶æ€ç¼–ç å™¨
            pattern_params = self.pattern_generator(encoded_state)
            # ç§»é™¤batchç»´åº¦
            pattern_params = pattern_params.squeeze(0)
        
        # å°†ç¥ç»ç½‘ç»œè¾“å‡ºè½¬æ¢ä¸ºæ¸¸æˆå‚æ•°
        pattern = self._decode_pattern(pattern_params)
        
        return pattern
    
    def _decode_pattern(self, pattern_params: torch.Tensor) -> Dict[str, Any]:
        """å°†ç¥ç»ç½‘ç»œè¾“å‡ºè§£ç ä¸ºæ¸¸æˆå‚æ•°"""
        params = pattern_params.cpu().numpy()
        
        # æ•Œæœºç”Ÿæˆæ¨¡å¼
        pattern_type_idx = int(params[0] * 4)  # 0-4å¯¹åº”5ç§æ¨¡å¼
        pattern_types = ['wave', 'spiral', 'formation', 'random', 'chaos']
        pattern_type = pattern_types[pattern_type_idx]
        
        # æ ¹æ®æ¨¡å¼ç±»å‹ç”Ÿæˆå…·ä½“å‚æ•°
        if pattern_type == 'wave':
            return {
                'type': 'wave',
                'wave_count': int(params[1] * 5) + 3,      # 3-8æ³¢
                'enemies_per_wave': int(params[2] * 10) + 5,  # 5-15ä¸ª
                'wave_delay': params[3] * 3 + 2,           # 2-5ç§’
                'enemy_speed': int(params[4] * 4) + 1,     # 1-5é€Ÿåº¦
                'enemy_health': int(params[5] * 4) + 1,    # 1-5ç”Ÿå‘½å€¼
                'enemy_behavior': self._select_behavior(params[6])
            }
        elif pattern_type == 'spiral':
            return {
                'type': 'spiral',
                'spiral_arms': int(params[1] * 4) + 2,     # 2-6è‡‚
                'enemies_per_arm': int(params[2] * 12) + 8,  # 8-20ä¸ª
                'spiral_tightness': params[3] * 1.5 + 0.5,   # 0.5-2.0
                'enemy_speed': int(params[4] * 4) + 1,
                'enemy_health': int(params[5] * 4) + 1,
                'enemy_behavior': self._select_behavior(params[6])
            }
        elif pattern_type == 'formation':
            return {
                'type': 'formation',
                'formation_type': self._select_formation(params[1]),
                'formation_size': int(params[2] * 4) + 3,   # 3-7ä¸ª
                'formation_spacing': params[3] * 100 + 50,   # 50-150
                'enemy_speed': int(params[4] * 4) + 1,
                'enemy_health': int(params[5] * 4) + 1,
                'enemy_behavior': self._select_behavior(params[6])
            }
        else:  # random, chaos
            return {
                'type': pattern_type,
                'enemy_count': int(params[1] * 30) + 20,    # 20-50ä¸ª
                'spawn_interval': params[2] * 1.5 + 0.5,   # 0.5-2.0ç§’
                'enemy_speed': int(params[3] * 4) + 1,
                'enemy_health': int(params[4] * 4) + 1,
                'enemy_behavior': self._select_behavior(params[5])
            }
    
    def _select_behavior(self, param: float) -> str:
        """æ ¹æ®å‚æ•°é€‰æ‹©æ•Œæœºè¡Œä¸º"""
        behaviors = ['straight', 'zigzag', 'circle', 'chase', 'evade']
        idx = int(param * len(behaviors))
        return behaviors[min(idx, len(behaviors) - 1)]
    
    def _select_formation(self, param: float) -> str:
        """æ ¹æ®å‚æ•°é€‰æ‹©ç¼–é˜Ÿç±»å‹"""
        formations = ['v', 'square', 'triangle', 'diamond']
        idx = int(param * len(formations))
        return formations[min(idx, len(formations) - 1)]
    
    def learn_from_experience(self, game_state: Dict[str, Any], 
                            generated_pattern: Dict[str, Any], 
                            game_outcome: Dict[str, Any]):
        """ä»æ¸¸æˆç»éªŒä¸­å­¦ä¹ """
        # è®¡ç®—å¥–åŠ±
        reward = self._calculate_reward(game_outcome)
        
        # å­˜å‚¨ç»éªŒ
        experience = {
            'state': game_state,
            'pattern': generated_pattern,
            'reward': reward,
            'outcome': game_outcome
        }
        self.experience_buffer.append(experience)
        
        # å¦‚æœç»éªŒè¶³å¤Ÿï¼Œè¿›è¡Œå­¦ä¹ 
        if len(self.experience_buffer) >= 100:
            self._train_models()
    
    def _calculate_reward(self, game_outcome: Dict[str, Any]) -> float:
        """è®¡ç®—æ¸¸æˆç»“æœçš„å¥–åŠ±"""
        reward = 0.0
        
        # ç”Ÿå­˜æ—¶é—´å¥–åŠ±
        survival_time = game_outcome.get('survival_time', 0)
        reward += min(survival_time / 60.0, 1.0) * 10  # æœ€å¤š10åˆ†
        
        # å‡»æ€å¥–åŠ±
        enemies_killed = game_outcome.get('enemies_killed', 0)
        reward += min(enemies_killed / 20.0, 1.0) * 5   # æœ€å¤š5åˆ†
        
        # åˆ†æ•°å¥–åŠ±
        score = game_outcome.get('score', 0)
        reward += min(score / 1000.0, 1.0) * 3          # æœ€å¤š3åˆ†
        
        # æƒ©ç½šé¡¹
        damage_taken = game_outcome.get('damage_taken', 0)
        reward -= min(damage_taken / 100.0, 1.0) * 2    # æœ€å¤šæ‰£2åˆ†
        
        return reward
    
    def _train_models(self):
        """è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹"""
        if len(self.experience_buffer) < 100:
            return
        
        # éšæœºé‡‡æ ·ç»éªŒ
        batch_size = min(32, len(self.experience_buffer))
        batch = random.sample(self.experience_buffer, batch_size)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        states = []
        rewards = []
        
        for exp in batch:
            states.append(self.encode_game_state(exp['state']))
            rewards.append(exp['reward'])
        
        states = torch.stack(states)
        rewards = torch.FloatTensor(rewards).to(self.device)
        
        # è®­ç»ƒçŠ¶æ€ç¼–ç å™¨
        self.encoder_optimizer.zero_grad()
        encoded_states = self.state_encoder(states)
        encoder_loss = self.encoder_criterion(encoded_states.mean(dim=0), 
                                           rewards.mean().expand(encoded_states.size(1)))
        encoder_loss.backward()
        self.encoder_optimizer.step()
        
        # è®­ç»ƒæ¨¡å¼ç”Ÿæˆå™¨
        self.generator_optimizer.zero_grad()
        generated_patterns = self.pattern_generator(encoded_states)
        generator_loss = self.generator_criterion(generated_patterns.mean(dim=0), 
                                               rewards.mean().expand(generated_patterns.size(1)))
        generator_loss.backward()
        self.generator_optimizer.step()
        
        print(f"ğŸ¤– æ¨¡å‹è®­ç»ƒå®Œæˆ - ç¼–ç å™¨æŸå¤±: {encoder_loss.item():.4f}, ç”Ÿæˆå™¨æŸå¤±: {generator_loss.item():.4f}")
    
    def save_model(self, model_path: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save({
            'state_encoder': self.state_encoder.state_dict(),
            'pattern_generator': self.pattern_generator.state_dict(),
            'encoder_optimizer': self.encoder_optimizer.state_dict(),
            'generator_optimizer': self.generator_optimizer.state_dict(),
        }, model_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    def load_model(self, model_path: str):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(model_path, map_location=self.device)
        self.state_encoder.load_state_dict(checkpoint['state_encoder'])
        self.pattern_generator.load_state_dict(checkpoint['pattern_generator'])
        self.encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer'])
        self.generator_optimizer.load_state_dict(checkpoint['generator_optimizer'])
        print(f"âœ… æ¨¡å‹å·²ä» {model_path} åŠ è½½")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºMLæ¸¸æˆAI
    ml_ai = MLGameAI()
    
    # æ¨¡æ‹Ÿæ¸¸æˆçŠ¶æ€
    game_state = {
        'player_health': 75,
        'player_score': 450,
        'enemies_killed': 12,
        'survival_time': 45,
        'enemies': [{'speed': 3, 'health': 2}] * 8,
        'power_ups': [{'type': 'health'}] * 2,
        'ai_difficulty': 1.2,
        'player_performance': 0.7
    }
    
    # ç”Ÿæˆæ¸¸æˆæ¨¡å¼
    pattern = ml_ai.generate_game_pattern(game_state)
    print(f"ğŸ® ç”Ÿæˆçš„æ¸¸æˆæ¨¡å¼: {pattern}")
    
    # æ¨¡æ‹Ÿæ¸¸æˆç»“æœ
    game_outcome = {
        'survival_time': 67,
        'enemies_killed': 18,
        'score': 720,
        'damage_taken': 45
    }
    
    # å­¦ä¹ 
    ml_ai.learn_from_experience(game_state, pattern, game_outcome)
    
    # ä¿å­˜æ¨¡å‹
    ml_ai.save_model('./models/ml_game_ai.pth')
