#!/usr/bin/env python3
"""
Background Removal Tool - ä½¿ç”¨AIæ¨¡å‹è¯†åˆ«å›¾ç‰‡ä¸»é¢˜å¹¶å»é™¤èƒŒæ™¯
æ”¯æŒå¤šç§AIæ¨¡å‹ï¼šRemBGã€SAMã€OpenCVç­‰
"""

import os
import sys
import pygame
import numpy as np
from PIL import Image
import io
import threading
import time

try:
    import rembg
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False
    print("RemBG not available. Install with: pip install rembg")

try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False
    print("OpenCV not available. Install with: pip install opencv-python")

try:
    from segment_anything import sam_model_registry, SamPredictor
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False
    print("SAM not available. Install with: pip install segment-anything")

class BackgroundRemover:
    """AIèƒŒæ™¯å»é™¤å·¥å…·ç±»"""
    
    def __init__(self):
        self.available_models = []
        self.current_model = None
        self.sam_predictor = None
        
        # æ£€æŸ¥å¯ç”¨çš„æ¨¡å‹
        self._check_available_models()
        
        # è®¾ç½®é»˜è®¤æ¨¡å‹
        if self.available_models:
            self.current_model = self.available_models[0]
    
    def _check_available_models(self):
        """æ£€æŸ¥å¯ç”¨çš„AIæ¨¡å‹"""
        # æŒ‰è´¨é‡ä¼˜å…ˆçº§æ’åºï¼šRemBG > SAM > OpenCV
        if REMBG_AVAILABLE:
            self.available_models.append('rembg')
            print("âœ“ RemBG model available - æœ€é«˜è´¨é‡AIæŠ å›¾")
        
        if SAM_AVAILABLE:
            self.available_models.append('sam')
            print("âœ“ SAM model available - Metaå…ˆè¿›åˆ†å‰²æ¨¡å‹")
        
        if OPENCV_AVAILABLE:
            self.available_models.append('opencv')
            print("âœ“ OpenCV model available - åŸºç¡€å›¾åƒå¤„ç†")
        
        if not self.available_models:
            print("âš  No AI models available. Please install at least one:")
            print("  pip install rembg")
            print("  pip install opencv-python")
            print("  pip install segment-anything")
    
    def set_model(self, model_name):
        """è®¾ç½®å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
        if model_name in self.available_models:
            self.current_model = model_name
            print(f"Switched to {model_name} model")
            return True
        else:
            print(f"Model {model_name} not available")
            return False
    
    def get_available_models(self):
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        return self.available_models.copy()
    
    def remove_background_rembg(self, image_path, output_path=None):
        """ä½¿ç”¨RemBGå»é™¤èƒŒæ™¯ - æœ€é«˜è´¨é‡AIæŠ å›¾ï¼ˆAIæ™ºèƒ½ç‰ˆï¼‰"""
        if not REMBG_AVAILABLE:
            raise ImportError("RemBG not available")
        
        try:
            print(f"ğŸ“– è¯»å–å›¾ç‰‡: {image_path}")
            # è¯»å–å›¾ç‰‡
            with open(image_path, 'rb') as f:
                input_data = f.read()
            
            # AIæ™ºèƒ½å‚æ•°é€‰æ‹©
            print(f"ğŸ§  å¼€å§‹AIæ™ºèƒ½å‚æ•°åˆ†æ...")
            complexity_score = self._analyze_image_complexity(image_path)
            print(f"ğŸ“Š å›¾ç‰‡å¤æ‚åº¦è¯„åˆ†: {complexity_score:.1f}/100")
            
            # æ ¹æ®å¤æ‚åº¦é€‰æ‹©æœ€ä½³å‚æ•°
            output_data = self._rembg_with_adaptive_params(input_data, complexity_score)
            
            # åå¤„ç†ä¼˜åŒ–
            print(f"ğŸ”§ å¼€å§‹AIæ™ºèƒ½åå¤„ç†ä¼˜åŒ–...")
            optimized_data = self._post_process_rembg_result(output_data, image_path, complexity_score)
            
            # ä¿å­˜ç»“æœ
            if output_path:
                print(f"ğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_path}")
                with open(output_path, 'wb') as f:
                    f.write(optimized_data)
                
                # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    print(f"ğŸ“ æ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå¤§å°: {file_size} bytes")
                    
                    # éªŒè¯æŠ å›¾è´¨é‡
                    quality_score = self._validate_rembg_quality(output_path)
                    print(f"ğŸ¯ æŠ å›¾è´¨é‡è¯„åˆ†: {quality_score:.1f}/100")
                    
                    return output_path
                else:
                    print("âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥")
                    return None
            else:
                # è¿”å›PIL Imageå¯¹è±¡
                print("ğŸ–¼ï¸ è¿”å›PIL Imageå¯¹è±¡")
                return Image.open(io.BytesIO(optimized_data))
                
        except Exception as e:
            print(f"âŒ RemBGèƒŒæ™¯å»é™¤å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _analyze_image_complexity(self, image_path):
        """åˆ†æå›¾ç‰‡å¤æ‚åº¦ - AIæ™ºèƒ½åˆ†æ"""
        try:
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                return 50.0
            
            # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œåˆ†æ
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # 1. è¾¹ç¼˜å¤æ‚åº¦åˆ†æ
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size * 100
            
            # 2. çº¹ç†å¤æ‚åº¦åˆ†æ
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            texture_variance = np.var(laplacian)
            
            # 3. è‰²å½©å¤æ‚åº¦åˆ†æ
            if len(image.shape) == 3:
                color_variance = np.var(image, axis=(0, 1))
                total_color_variance = np.sum(color_variance)
            else:
                total_color_variance = 0
            
            # 4. å±€éƒ¨æ–¹å·®åˆ†æï¼ˆæ£€æµ‹ç»†èŠ‚ä¸°å¯Œåº¦ï¼‰
            local_var = cv2.GaussianBlur(gray.astype(np.float32), (15, 15), 3)
            local_variance = np.var(local_var)
            
            # 5. æ¢¯åº¦å¤æ‚åº¦åˆ†æ
            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            avg_gradient = np.mean(gradient_magnitude)
            
            # 6. AIç”Ÿæˆå›¾ç‰‡ç‰¹å¾æ£€æµ‹
            ai_features = self._detect_ai_generation_features(image)
            
            # ç»¼åˆå¤æ‚åº¦è¯„åˆ†
            complexity_score = (
                edge_density * 0.25 +
                min(texture_variance / 1000, 25) +
                min(total_color_variance / 10000, 20) +
                min(local_variance / 100, 15) +
                min(avg_gradient / 10, 15)
            )
            
            # AIç‰¹å¾è°ƒæ•´
            if ai_features['is_likely_ai_generated']:
                complexity_score *= 1.2  # AIç”Ÿæˆçš„å›¾ç‰‡é€šå¸¸æ›´å¤æ‚
                print(f"ğŸ¨ æ£€æµ‹åˆ°AIç”Ÿæˆå›¾ç‰‡ç‰¹å¾ï¼Œå¤æ‚åº¦æå‡20%")
            
            return min(complexity_score, 100.0)
            
        except Exception as e:
            print(f"âš  å¤æ‚åº¦åˆ†æå¤±è´¥: {e}")
            return 50.0
    
    def _detect_ai_generation_features(self, image):
        """æ£€æµ‹AIç”Ÿæˆå›¾ç‰‡çš„ç‰¹å¾"""
        try:
            # è½¬æ¢ä¸ºRGBè¿›è¡Œåˆ†æ
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # 1. è‰²å½©è¿‡æ¸¡å¹³æ»‘æ€§æ£€æµ‹
            diff_x = np.diff(image_rgb, axis=1)
            diff_y = np.diff(image_rgb, axis=0)
            avg_diff_x = np.mean(np.abs(diff_x))
            avg_diff_y = np.mean(np.abs(diff_y))
            
            # 2. è‰²å½©é¥±å’Œåº¦åˆ†æ
            hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)
            saturation = hsv[:, :, 1]
            avg_saturation = np.mean(saturation)
            
            # 3. è¾¹ç¼˜å¹³æ»‘åº¦åˆ†æ
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            laplacian_variance = np.var(laplacian)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºAIç”Ÿæˆå›¾ç‰‡
            is_smooth = (avg_diff_x < 15 and avg_diff_y < 15)
            is_high_saturation = avg_saturation > 100
            is_smooth_edges = laplacian_variance < 5000
            
            is_likely_ai_generated = (is_smooth and is_high_saturation) or is_smooth_edges
            
            return {
                'is_likely_ai_generated': is_likely_ai_generated,
                'smoothness_score': max(0, 1 - (avg_diff_x + avg_diff_y) / 200),
                'saturation_score': avg_saturation / 255,
                'edge_smoothness': max(0, 1 - laplacian_variance / 10000)
            }
            
        except Exception as e:
            print(f"âš  AIç‰¹å¾æ£€æµ‹å¤±è´¥: {e}")
            return {'is_likely_ai_generated': False, 'smoothness_score': 0.5, 'saturation_score': 0.5, 'edge_smoothness': 0.5}
    
    def _rembg_with_adaptive_params(self, input_data, complexity_score):
        """ä½¿ç”¨è‡ªé€‚åº”å‚æ•°çš„RemBGæŠ å›¾"""
        try:
            print(f"ğŸ¯ æ ¹æ®å¤æ‚åº¦é€‰æ‹©æœ€ä½³å‚æ•°...")
            
            if complexity_score > 80:
                # æé«˜å¤æ‚åº¦ï¼šæœ€ä¿å®ˆçš„å‚æ•°
                print(f"ğŸ”´ æé«˜å¤æ‚åº¦ï¼Œä½¿ç”¨æœ€ä¿å®ˆå‚æ•°")
                output_data = rembg.remove(input_data, 
                                         alpha_matting=True,
                                         alpha_matting_foreground_threshold=250,
                                         alpha_matting_background_threshold=5,
                                         alpha_matting_erode_size=25)
            elif complexity_score > 70:
                # é«˜å¤æ‚åº¦ï¼šä¿å®ˆå‚æ•°
                print(f"ğŸŸ  é«˜å¤æ‚åº¦ï¼Œä½¿ç”¨ä¿å®ˆå‚æ•°")
                output_data = rembg.remove(input_data, 
                                         alpha_matting=True,
                                         alpha_matting_foreground_threshold=245,
                                         alpha_matting_background_threshold=8,
                                         alpha_matting_erode_size=20)
            elif complexity_score > 50:
                # ä¸­ç­‰å¤æ‚åº¦ï¼šå¹³è¡¡å‚æ•°
                print(f"ğŸŸ¡ ä¸­ç­‰å¤æ‚åº¦ï¼Œä½¿ç”¨å¹³è¡¡å‚æ•°")
                output_data = rembg.remove(input_data, 
                                         alpha_matting=True,
                                         alpha_matting_foreground_threshold=240,
                                         alpha_matting_background_threshold=12,
                                         alpha_matting_erode_size=15)
            else:
                # ä½å¤æ‚åº¦ï¼šæ ‡å‡†å‚æ•°
                print(f"ğŸŸ¢ ä½å¤æ‚åº¦ï¼Œä½¿ç”¨æ ‡å‡†å‚æ•°")
                output_data = rembg.remove(input_data, 
                                         alpha_matting=True,
                                         alpha_matting_foreground_threshold=235,
                                         alpha_matting_background_threshold=15,
                                         alpha_matting_erode_size=10)
            
            print(f"âœ… è‡ªé€‚åº”å‚æ•°AIæŠ å›¾å®Œæˆï¼")
            return output_data
            
        except Exception as e:
            print(f"âš  è‡ªé€‚åº”å‚æ•°å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†å‚æ•°: {e}")
            # å›é€€åˆ°æ ‡å‡†å‚æ•°
            return rembg.remove(input_data)
    
    def _post_process_rembg_result(self, output_data, original_image_path, complexity_score):
        """åå¤„ç†RemBGç»“æœï¼Œä¼˜åŒ–æŠ å›¾è´¨é‡ï¼ˆAIæ™ºèƒ½ç‰ˆï¼‰"""
        try:
            # å°†è¾“å‡ºæ•°æ®è½¬æ¢ä¸ºPIL Image
            output_image = Image.open(io.BytesIO(output_data))
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            output_array = np.array(output_image)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰Alphaé€šé“
            if len(output_array.shape) == 3 and output_array.shape[2] == 4:
                # æå–Alphaé€šé“
                alpha = output_array[:, :, 3]
                
                # æ£€æµ‹æ˜¯å¦è¿‡åº¦æŠ å›¾
                foreground_ratio = np.sum(alpha > 128) / alpha.size * 100
                print(f"ğŸ“Š å½“å‰å‰æ™¯åŒºåŸŸ: {foreground_ratio:.1f}%")
                
                # æ ¹æ®å¤æ‚åº¦è°ƒæ•´ä¼˜åŒ–ç­–ç•¥
                if foreground_ratio < 30:  # å‰æ™¯åŒºåŸŸè¿‡å°ï¼Œå¯èƒ½å­˜åœ¨è¿‡åº¦æŠ å›¾
                    print(f"âš  æ£€æµ‹åˆ°è¿‡åº¦æŠ å›¾ï¼Œå¼€å§‹AIæ™ºèƒ½ä¼˜åŒ–...")
                    
                    # ä¼˜åŒ–ç­–ç•¥1: æ™ºèƒ½å‰æ™¯æ‰©å±•
                    optimized_alpha = self._expand_foreground_smart(alpha, complexity_score)
                    
                    # ä¼˜åŒ–ç­–ç•¥2: æ™ºèƒ½è¾¹ç¼˜ä¼˜åŒ–
                    optimized_alpha = self._smooth_edges_smart(optimized_alpha, complexity_score)
                    
                    # åº”ç”¨ä¼˜åŒ–åçš„Alphaé€šé“
                    output_array[:, :, 3] = optimized_alpha
                    
                    new_ratio = np.sum(optimized_alpha > 128) / optimized_alpha.size * 100
                    print(f"âœ… AIæ™ºèƒ½ä¼˜åŒ–å®Œæˆï¼Œå‰æ™¯åŒºåŸŸ: {foreground_ratio:.1f}% â†’ {new_ratio:.1f}%")
                
                # ä¼˜åŒ–ç­–ç•¥3: æ™ºèƒ½è‰²å½©å¢å¼º
                output_array = self._enhance_colors_smart(output_array, complexity_score)
                
                # ä¼˜åŒ–ç­–ç•¥4: AIç»†èŠ‚æ¢å¤ï¼ˆä»…å¯¹é«˜å¤æ‚åº¦å›¾ç‰‡ï¼‰
                if complexity_score > 70:
                    output_array = self._restore_ai_details(output_array, original_image_path)
                
                # æ–°å¢ï¼šå»é™¤é»‘è‰²é˜´å½±ä¼˜åŒ–
                output_array = self._remove_black_shadows(output_array)
                
            # è½¬æ¢å›PIL Image
            optimized_image = Image.fromarray(output_array, 'RGBA')
            
            # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
            output_buffer = io.BytesIO()
            optimized_image.save(output_buffer, format='PNG')
            optimized_data = output_buffer.getvalue()
            
            return optimized_data
            
        except Exception as e:
            print(f"âš  åå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ: {e}")
            return output_data
    
    def _expand_foreground(self, alpha):
        """æ‰©å¤§å‰æ™¯åŒºåŸŸï¼Œè§£å†³è¿‡åº¦æŠ å›¾é—®é¢˜"""
        try:
            # åˆ›å»ºå‰æ™¯æ©ç 
            foreground_mask = alpha > 128
            
            # ä½¿ç”¨å½¢æ€å­¦è†¨èƒ€æ“ä½œæ‰©å¤§å‰æ™¯
            kernel = np.ones((5, 5), np.uint8)
            expanded_mask = cv2.dilate(foreground_mask.astype(np.uint8), kernel, iterations=2)
            
            # ä½¿ç”¨é«˜æ–¯æ¨¡ç³Šåˆ›å»ºå¹³æ»‘è¿‡æ¸¡
            expanded_mask = cv2.GaussianBlur(expanded_mask.astype(np.float32), (15, 15), 3)
            
            # é‡æ–°æ˜ å°„åˆ°0-255èŒƒå›´
            expanded_alpha = (expanded_mask * 255).astype(np.uint8)
            
            return expanded_alpha
            
        except Exception as e:
            print(f"âš  å‰æ™¯æ‰©å±•å¤±è´¥: {e}")
            return alpha
    
    def _expand_foreground_smart(self, alpha, complexity_score):
        """æ™ºèƒ½å‰æ™¯æ‰©å±•ï¼Œæ ¹æ®å¤æ‚åº¦è°ƒæ•´ç­–ç•¥"""
        try:
            # åˆ›å»ºå‰æ™¯æ©ç 
            foreground_mask = alpha > 128
            
            # æ ¹æ®å¤æ‚åº¦è°ƒæ•´æ‰©å±•å‚æ•° - å¾®è°ƒä¼˜åŒ–ç‰ˆæœ¬
            if complexity_score > 80:
                # æé«˜å¤æ‚åº¦ï¼šè½»å¾®æ‰©å±•
                kernel_size = 3
                iterations = 1
                blur_sigma = 1
                print(f"ğŸ”´ æé«˜å¤æ‚åº¦ï¼Œä½¿ç”¨è½»å¾®å‰æ™¯æ‰©å±•")
            elif complexity_score > 70:
                # é«˜å¤æ‚åº¦ï¼šå¾ˆè½»å¾®æ‰©å±•
                kernel_size = 3
                iterations = 1
                blur_sigma = 0.8
                print(f"ğŸŸ  é«˜å¤æ‚åº¦ï¼Œä½¿ç”¨å¾ˆè½»å¾®å‰æ™¯æ‰©å±•")
            elif complexity_score > 50:
                # ä¸­ç­‰å¤æ‚åº¦ï¼šå‡ ä¹ä¸æ‰©å±•
                kernel_size = 3
                iterations = 1
                blur_sigma = 0.5
                print(f"ğŸŸ¡ ä¸­ç­‰å¤æ‚åº¦ï¼Œå‡ ä¹ä¸æ‰©å±•")
            else:
                # ä½å¤æ‚åº¦ï¼šå®Œå…¨ä¸æ‰©å±•
                kernel_size = 1
                iterations = 0
                blur_sigma = 0
                print(f"ğŸŸ¢ ä½å¤æ‚åº¦ï¼Œå®Œå…¨ä¸æ‰©å±•")
            
            # ä½¿ç”¨å½¢æ€å­¦è†¨èƒ€æ“ä½œæ‰©å¤§å‰æ™¯
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            expanded_mask = cv2.dilate(foreground_mask.astype(np.uint8), kernel, iterations=iterations)
            
            # ä½¿ç”¨é«˜æ–¯æ¨¡ç³Šåˆ›å»ºå¹³æ»‘è¿‡æ¸¡
            expanded_mask = cv2.GaussianBlur(expanded_mask.astype(np.float32), (15, 15), blur_sigma)
            
            # é‡æ–°æ˜ å°„åˆ°0-255èŒƒå›´
            expanded_alpha = (expanded_mask * 255).astype(np.uint8)
            
            return expanded_alpha
            
        except Exception as e:
            print(f"âš  æ™ºèƒ½å‰æ™¯æ‰©å±•å¤±è´¥: {e}")
            return alpha
    
    def _smooth_edges(self, alpha):
        """å¹³æ»‘è¾¹ç¼˜ï¼Œæ”¹å–„æŠ å›¾è´¨é‡"""
        try:
            # ä½¿ç”¨åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜çš„åŒæ—¶å¹³æ»‘åŒºåŸŸ
            smoothed = cv2.bilateralFilter(alpha, 9, 75, 75)
            
            # è½»å¾®çš„é«˜æ–¯æ¨¡ç³Šè¿›ä¸€æ­¥å¹³æ»‘
            smoothed = cv2.GaussianBlur(smoothed.astype(np.float32), (5, 5), 1)
            
            return smoothed.astype(np.uint8)
            
        except Exception as e:
            print(f"âš  è¾¹ç¼˜å¹³æ»‘å¤±è´¥: {e}")
            return alpha
    
    def _smooth_edges_smart(self, alpha, complexity_score):
        """æ™ºèƒ½è¾¹ç¼˜å¹³æ»‘ï¼Œæ ¹æ®å¤æ‚åº¦è°ƒæ•´ç­–ç•¥"""
        try:
            # æ ¹æ®å¤æ‚åº¦è°ƒæ•´è¾¹ç¼˜å¹³æ»‘å‚æ•° - å¾®è°ƒä¼˜åŒ–ç‰ˆæœ¬
            if complexity_score > 80:
                # æé«˜å¤æ‚åº¦ï¼šå¾ˆè½»å¾®è¾¹ç¼˜å¤„ç†
                bilateral_d = 3
                bilateral_sigma_color = 30
                bilateral_sigma_space = 30
                gaussian_kernel = 3
                gaussian_sigma = 0.1
                print(f"ğŸ”´ æé«˜å¤æ‚åº¦ï¼Œä½¿ç”¨å¾ˆè½»å¾®è¾¹ç¼˜å¹³æ»‘")
            elif complexity_score > 70:
                # é«˜å¤æ‚åº¦ï¼šå‡ ä¹ä¸å¹³æ»‘
                bilateral_d = 3
                bilateral_sigma_color = 25
                bilateral_sigma_space = 25
                gaussian_kernel = 3
                gaussian_sigma = 0.05
                print(f"ğŸŸ  é«˜å¤æ‚åº¦ï¼Œå‡ ä¹ä¸å¹³æ»‘")
            elif complexity_score > 50:
                # ä¸­ç­‰å¤æ‚åº¦ï¼šå‡ ä¹ä¸å¹³æ»‘
                bilateral_d = 3
                bilateral_sigma_color = 20
                bilateral_sigma_space = 20
                gaussian_kernel = 3
                gaussian_sigma = 0.02
                print(f"ğŸŸ¡ ä¸­ç­‰å¤æ‚åº¦ï¼Œå‡ ä¹ä¸å¹³æ»‘")
            else:
                # ä½å¤æ‚åº¦ï¼šå®Œå…¨ä¸å¹³æ»‘
                bilateral_d = 1
                bilateral_sigma_color = 10
                bilateral_sigma_space = 10
                gaussian_kernel = 1
                gaussian_sigma = 0.01
                print(f"ğŸŸ¢ ä½å¤æ‚åº¦ï¼Œå®Œå…¨ä¸å¹³æ»‘")
            
            # ä½¿ç”¨åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜çš„åŒæ—¶å¹³æ»‘åŒºåŸŸ
            smoothed = cv2.bilateralFilter(alpha, bilateral_d, bilateral_sigma_color, bilateral_sigma_space)
            
            # è½»å¾®çš„é«˜æ–¯æ¨¡ç³Šè¿›ä¸€æ­¥å¹³æ»‘
            smoothed = cv2.GaussianBlur(smoothed.astype(np.float32), (gaussian_kernel, gaussian_kernel), gaussian_sigma)
            
            return smoothed.astype(np.uint8)
            
        except Exception as e:
            print(f"âš  æ™ºèƒ½è¾¹ç¼˜å¹³æ»‘å¤±è´¥: {e}")
            return alpha
    
    def _enhance_colors(self, rgba_array):
        """å¢å¼ºè‰²å½©ï¼Œæ”¹å–„è§†è§‰æ•ˆæœ"""
        try:
            # åªå¤„ç†RGBé€šé“
            rgb = rgba_array[:, :, :3].astype(np.float32)
            
            # è½»å¾®çš„è‰²å½©å¢å¼º
            # å¢åŠ é¥±å’Œåº¦
            hsv = cv2.cvtColor(rgb.astype(np.uint8), cv2.COLOR_RGB2HSV).astype(np.float32)
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.1, 0, 255)  # å¢åŠ é¥±å’Œåº¦10%
            enhanced_rgb = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
            
            # åº”ç”¨å¢å¼ºåçš„RGB
            rgba_array[:, :, :3] = enhanced_rgb
            
            return rgba_array
            
        except Exception as e:
            print(f"âš  è‰²å½©å¢å¼ºå¤±è´¥: {e}")
            return rgba_array
    
    def _remove_black_shadows(self, rgba_array):
        """å»é™¤é»‘è‰²é˜´å½±ï¼Œä¼˜åŒ–æŠ å›¾è¾¹ç¼˜ - å¹³è¡¡ç‰ˆæœ¬"""
        try:
            # æå–Alphaé€šé“
            alpha = rgba_array[:, :, 3]
            
            # åˆ›å»ºå‰æ™¯æ©ç  - å¾®è°ƒä¼˜åŒ–ç‰ˆæœ¬
            foreground_mask = alpha > 80  # è¿›ä¸€æ­¥æé«˜é˜ˆå€¼ï¼Œåªå¤„ç†æ ¸å¿ƒå‰æ™¯åŒºåŸŸ
            
            # å¯¹å‰æ™¯åŒºåŸŸè¿›è¡Œé»‘è‰²é˜´å½±æ£€æµ‹å’Œå»é™¤
            rgb = rgba_array[:, :, :3]
            
            # æ£€æµ‹é»‘è‰²åƒç´ ï¼ˆRGBå€¼éƒ½å¾ˆä½ï¼‰- æ›´ä¸¥æ ¼çš„é˜ˆå€¼
            black_threshold = 15  # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼ï¼Œåªå¤„ç†çœŸæ­£çš„æ·±é»‘è‰²åƒç´ 
            black_pixels = np.all(rgb < black_threshold, axis=2)
            
            # åªåœ¨å‰æ™¯åŒºåŸŸå†…å¤„ç†é»‘è‰²åƒç´ 
            black_in_foreground = black_pixels & foreground_mask
            
            if np.any(black_in_foreground):
                print(f"ğŸ” æ£€æµ‹åˆ° {np.sum(black_in_foreground)} ä¸ªé»‘è‰²åƒç´ ï¼Œå¼€å§‹ç²¾ç¡®ä¼˜åŒ–...")
                
                # æ–¹æ³•1: æ›´ç²¾ç¡®çš„é€æ˜åº¦è°ƒæ•´
                rgba_array[black_in_foreground, 3] = np.clip(alpha[black_in_foreground] * 0.8, 0, 255)
                
                # æ–¹æ³•2: åªå¯¹çœŸæ­£çš„è¾¹ç¼˜è¿›è¡Œæè½»å¾®ä¿®å¤
                edge_mask = (alpha > 80) & (alpha < 120)  # æ›´çª„çš„è¾¹ç¼˜èŒƒå›´
                if np.any(edge_mask):
                    print(f"ğŸ”§ å¯¹ {np.sum(edge_mask)} ä¸ªè¾¹ç¼˜åƒç´ è¿›è¡Œæè½»å¾®ä¿®å¤...")
                    
                    # ä½¿ç”¨æ›´å°çš„é‚»åŸŸï¼Œå‡å°‘å½±å“èŒƒå›´
                    for i in range(1, rgba_array.shape[0] - 1):
                        for j in range(1, rgba_array.shape[1] - 1):
                            if edge_mask[i, j]:
                                # è·å–å‘¨å›´3x3åŒºåŸŸçš„æœ‰æ•ˆåƒç´ 
                                neighborhood = rgba_array[max(0, i-1):min(rgba_array.shape[0], i+2),
                                                        max(0, j-1):min(rgba_array.shape[1], j+2)]
                                valid_pixels = neighborhood[neighborhood[:, :, 3] > 180]  # æ›´é«˜çš„é€æ˜åº¦è¦æ±‚
                                
                                if len(valid_pixels) > 0:
                                    # ä½¿ç”¨åŠ æƒå¹³å‡ï¼Œä¿æŒåŸæœ‰é¢œè‰²ç‰¹å¾
                                    weights = valid_pixels[:, 3] / 255.0  # ä½¿ç”¨é€æ˜åº¦ä½œä¸ºæƒé‡
                                    weighted_avg = np.average(valid_pixels[:, :3], axis=0, weights=weights)
                                    
                                    # æ··åˆåŸæœ‰é¢œè‰²å’Œä¿®å¤é¢œè‰²ï¼Œä¿æŒ85%åŸæœ‰ç‰¹å¾
                                    original_color = rgba_array[i, j, :3]
                                    rgba_array[i, j, :3] = (original_color * 0.85 + weighted_avg * 0.15).astype(np.uint8)
                                    rgba_array[i, j, 3] = alpha[i, j]  # ä¿æŒåŸæœ‰é€æ˜åº¦
                
                print(f"âœ… ç²¾ç¡®é»‘è‰²é˜´å½±ä¼˜åŒ–å®Œæˆ")
            
            return rgba_array
            
        except Exception as e:
            print(f"âš  é»‘è‰²é˜´å½±å»é™¤å¤±è´¥: {e}")
            return rgba_array
    
    def _enhance_colors_smart(self, rgba_array, complexity_score):
        """æ™ºèƒ½è‰²å½©å¢å¼ºï¼Œæ ¹æ®å¤æ‚åº¦è°ƒæ•´ç­–ç•¥"""
        try:
            # åªå¤„ç†RGBé€šé“
            rgb = rgba_array[:, :, :3].astype(np.float32)
            
            # æ ¹æ®å¤æ‚åº¦è°ƒæ•´è‰²å½©å¢å¼ºå‚æ•° - å¾®è°ƒä¼˜åŒ–ç‰ˆæœ¬
            if complexity_score > 80:
                # æé«˜å¤æ‚åº¦ï¼šè½»å¾®è‰²å½©å¢å¼º
                saturation_factor = 1.08
                brightness_factor = 1.03
                print(f"ğŸ”´ æé«˜å¤æ‚åº¦ï¼Œä½¿ç”¨è½»å¾®è‰²å½©å¢å¼º")
            elif complexity_score > 70:
                # é«˜å¤æ‚åº¦ï¼šå¾ˆè½»å¾®è‰²å½©å¢å¼º
                saturation_factor = 1.05
                brightness_factor = 1.02
                print(f"ğŸŸ  é«˜å¤æ‚åº¦ï¼Œä½¿ç”¨å¾ˆè½»å¾®è‰²å½©å¢å¼º")
            elif complexity_score > 50:
                # ä¸­ç­‰å¤æ‚åº¦ï¼šå‡ ä¹ä¸å¢å¼º
                saturation_factor = 1.02
                brightness_factor = 1.01
                print(f"ğŸŸ¡ ä¸­ç­‰å¤æ‚åº¦ï¼Œå‡ ä¹ä¸å¢å¼º")
            else:
                # ä½å¤æ‚åº¦ï¼šå®Œå…¨ä¸å¢å¼º
                saturation_factor = 1.0
                brightness_factor = 1.0
                print(f"ğŸŸ¢ ä½å¤æ‚åº¦ï¼Œå®Œå…¨ä¸å¢å¼º")
            
            # è½¬æ¢ä¸ºHSV
            hsv = cv2.cvtColor(rgb.astype(np.uint8), cv2.COLOR_RGB2HSV).astype(np.float32)
            
            # å¢å¼ºé¥±å’Œåº¦
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * saturation_factor, 0, 255)
            
            # å¢å¼ºäº®åº¦
            hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)
            
            # è½¬æ¢å›RGB
            enhanced_rgb = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
            
            # åº”ç”¨å¢å¼ºåçš„RGB
            rgba_array[:, :, :3] = enhanced_rgb
            
            return rgba_array
            
        except Exception as e:
            print(f"âš  æ™ºèƒ½è‰²å½©å¢å¼ºå¤±è´¥: {e}")
            return rgba_array
    
    def _restore_ai_details(self, rgba_array, original_image_path):
        """AIç»†èŠ‚æ¢å¤ï¼Œä¸“é—¨é’ˆå¯¹é«˜å¤æ‚åº¦å›¾ç‰‡"""
        try:
            print(f"ğŸ” å¼€å§‹AIç»†èŠ‚æ¢å¤...")
            
            # è¯»å–åŸå§‹å›¾ç‰‡
            original = cv2.imread(original_image_path)
            if original is None:
                print("âš  æ— æ³•è¯»å–åŸå§‹å›¾ç‰‡ï¼Œè·³è¿‡ç»†èŠ‚æ¢å¤")
                return rgba_array
            
            # è½¬æ¢ä¸ºRGB
            original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
            
            # åˆ›å»ºç»†èŠ‚æ©ç ï¼ˆå®Œå…¨ä¸é€æ˜åŒºåŸŸï¼‰
            alpha = rgba_array[:, :, 3]
            detail_mask = (alpha > 200).astype(np.float32)
            
            # åœ¨å®Œå…¨ä¸é€æ˜åŒºåŸŸæ¢å¤åŸå§‹ç»†èŠ‚
            for i in range(3):
                rgba_array[:, :, i] = (rgba_array[:, :, i] * (1 - detail_mask) + 
                                      original_rgb[:, :, i] * detail_mask).astype(np.uint8)
            
            print(f"âœ… AIç»†èŠ‚æ¢å¤å®Œæˆ")
            return rgba_array
            
        except Exception as e:
            print(f"âš  AIç»†èŠ‚æ¢å¤å¤±è´¥: {e}")
            return rgba_array
    
    def _validate_rembg_quality(self, output_path):
        """éªŒè¯RemBGæŠ å›¾è´¨é‡"""
        try:
            # è¯»å–å¤„ç†åçš„å›¾ç‰‡
            processed = cv2.imread(output_path, cv2.IMREAD_UNCHANGED)
            if processed is None:
                return 0
            
            if len(processed.shape) == 3 and processed.shape[2] == 4:
                alpha = processed[:, :, 3]
                
                # è®¡ç®—è´¨é‡æŒ‡æ ‡
                foreground_ratio = np.sum(alpha > 128) / alpha.size * 100
                
                # å‰æ™¯åŒºåŸŸè¯„åˆ†ï¼ˆ30-70%ä¸ºç†æƒ³èŒƒå›´ï¼‰
                if 30 <= foreground_ratio <= 70:
                    foreground_score = 100
                elif foreground_ratio < 30:
                    foreground_score = max(0, 100 - (30 - foreground_ratio) * 3)
                else:
                    foreground_score = max(0, 100 - (foreground_ratio - 70) * 2)
                
                # è¾¹ç¼˜è´¨é‡è¯„åˆ†
                edge_quality = self._analyze_edge_quality(alpha)
                edge_score = edge_quality * 20  # è½¬æ¢ä¸º0-100åˆ†
                
                # ç»¼åˆè¯„åˆ†
                total_score = (foreground_score * 0.6 + edge_score * 0.4)
                
                return total_score
            
            return 0
            
        except Exception as e:
            print(f"âš  è´¨é‡éªŒè¯å¤±è´¥: {e}")
            return 0
    
    def _analyze_edge_quality(self, alpha_mask):
        """åˆ†æè¾¹ç¼˜è´¨é‡"""
        try:
            # ä½¿ç”¨Sobelç®—å­æ£€æµ‹è¾¹ç¼˜
            sobel_x = cv2.Sobel(alpha_mask, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(alpha_mask, cv2.CV_64F, 0, 1, ksize=3)
            
            # è®¡ç®—è¾¹ç¼˜å¼ºåº¦
            edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
            
            # è®¡ç®—å¹³å‡è¾¹ç¼˜å¼ºåº¦
            avg_edge_strength = np.mean(edge_magnitude)
            
            # è½¬æ¢ä¸º1-5åˆ†
            if avg_edge_strength < 10:
                return 1  # æ¨¡ç³Š
            elif avg_edge_strength < 30:
                return 2  # ä¸€èˆ¬
            elif avg_edge_strength < 60:
                return 3  # æ¸…æ™°
            elif avg_edge_strength < 100:
                return 4  # å¾ˆæ¸…æ™°
            else:
                return 5  # éå¸¸æ¸…æ™°
                
        except Exception as e:
            return 3  # é»˜è®¤ä¸­ç­‰è´¨é‡
    
    def remove_background_opencv(self, image_path, output_path=None):
        """ä½¿ç”¨OpenCVè¿›è¡ŒèƒŒæ™¯å»é™¤"""
        if not OPENCV_AVAILABLE:
            raise ImportError("OpenCV not available")
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(image_path)
            if file_size == 0:
                raise ValueError(f"å›¾ç‰‡æ–‡ä»¶ä¸ºç©º: {image_path}")
            
            print(f"æ­£åœ¨è¯»å–å›¾ç‰‡: {image_path} (å¤§å°: {file_size} bytes)")
            
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                # å°è¯•ä½¿ç”¨ç»å¯¹è·¯å¾„
                abs_path = os.path.abspath(image_path)
                print(f"å°è¯•ä½¿ç”¨ç»å¯¹è·¯å¾„: {abs_path}")
                image = cv2.imread(abs_path)
                
                if image is None:
                    # å°è¯•ä½¿ç”¨PILè¯»å–ç„¶åè½¬æ¢
                    print("OpenCVè¯»å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨PILè¯»å–...")
                    pil_image = Image.open(image_path)
                    # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                    image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
                    print("ä½¿ç”¨PILæˆåŠŸè¯»å–å›¾ç‰‡")
            
            if image is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
            
            print(f"å›¾ç‰‡è¯»å–æˆåŠŸï¼Œå°ºå¯¸: {image.shape}")
            
            # è½¬æ¢ä¸ºRGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # åˆ›å»ºæ©ç 
            mask = self._create_mask_opencv(image_rgb)
            
            # åº”ç”¨æ©ç 
            result = self._apply_mask(image_rgb, mask)
            
            # ä¿å­˜ç»“æœ
            if output_path:
                # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰Alphaé€šé“
                if len(result.shape) == 3 and result.shape[2] == 4:
                    print(f"æ£€æµ‹åˆ°4é€šé“å›¾ç‰‡ï¼Œä½¿ç”¨PILä¿å­˜RGBA")
                    # æœ‰Alphaé€šé“ï¼Œä½¿ç”¨PILä¿å­˜ä»¥ä¿æŒé€æ˜åº¦
                    try:
                        pil_image = Image.fromarray(result, 'RGBA')
                        pil_image.save(output_path, 'PNG')
                        print(f"âœ“ ä½¿ç”¨PILä¿å­˜RGBAå›¾ç‰‡æˆåŠŸ: {output_path}")
                        print(f"ä¿å­˜çš„å›¾ç‰‡å°ºå¯¸: {result.shape}, Alphaé€šé“èŒƒå›´: {np.min(result[:, :, 3])} - {np.max(result[:, :, 3])}")
                    except Exception as e:
                        print(f"âŒ PILä¿å­˜å¤±è´¥: {e}")
                        # å¤‡ç”¨æ–¹æ³•ï¼šè½¬æ¢ä¸ºBGRä¿å­˜
                        result_bgr = cv2.cvtColor(result, cv2.COLOR_RGBA2BGR)
                        cv2.imwrite(output_path, result_bgr)
                        print(f"ä½¿ç”¨OpenCVå¤‡ç”¨ä¿å­˜")
                else:
                    print(f"æ£€æµ‹åˆ°{len(result.shape)}é€šé“å›¾ç‰‡ï¼Œä½¿ç”¨OpenCVä¿å­˜")
                    # æ²¡æœ‰Alphaé€šé“ï¼Œç›´æ¥ä¿å­˜
                    cv2.imwrite(output_path, result)
                
                return output_path
            else:
                return Image.fromarray(result)
                
        except Exception as e:
            print(f"OpenCV background removal failed: {e}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {type(e).__name__}: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def _create_mask_opencv(self, image):
        """ä½¿ç”¨OpenCVåˆ›å»ºæ©ç  - æ”¹è¿›ç‰ˆæœ¬"""
        try:
            # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
            hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
            
            # æ–¹æ³•1: æ”¹è¿›çš„é¢œè‰²é˜ˆå€¼æ–¹æ³•
            mask1 = self._create_color_mask(hsv)
            
            # æ–¹æ³•2: è¾¹ç¼˜æ£€æµ‹æ–¹æ³•
            mask2 = self._create_edge_mask(image)
            
            # æ–¹æ³•3: è½®å»“æ£€æµ‹æ–¹æ³•
            mask3 = self._create_contour_mask(image)
            
            # æ–¹æ³•4: å°è¯•GrabCutç®—æ³•ï¼ˆå¦‚æœå›¾ç‰‡è¶³å¤Ÿå¤§ï¼‰
            mask4 = None
            if image.shape[0] > 100 and image.shape[1] > 100:
                mask4 = self._create_grabcut_mask(image)
            
            # ç»„åˆæ‰€æœ‰æ©ç 
            combined_mask = self._combine_masks([mask1, mask2, mask3, mask4])
            
            # åå¤„ç†æ©ç 
            final_mask = self._post_process_mask(combined_mask)
            
            return final_mask
            
        except Exception as e:
            print(f"æ©ç åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
            # å¤‡ç”¨æ–¹æ³•ï¼šç®€å•çš„é¢œè‰²é˜ˆå€¼
            return self._create_simple_color_mask(hsv)
    
    def _create_color_mask(self, hsv):
        """åˆ›å»ºé¢œè‰²æ©ç  - æ”¹è¿›ç‰ˆæœ¬"""
        # æ‰©å±•çš„é¢œè‰²èŒƒå›´ï¼ŒåŒ…æ‹¬æ›´å¤šèƒŒæ™¯é¢œè‰²
        color_ranges = [
            # è“è‰²å¤©ç©º
            (np.array([100, 50, 50]), np.array([130, 255, 255])),
            # æµ…è“è‰²
            (np.array([90, 30, 100]), np.array([110, 255, 255])),
            # ç™½è‰²äº‘æœµ
            (np.array([0, 0, 200]), np.array([180, 30, 255])),
            # æµ…ç°è‰²
            (np.array([0, 0, 150]), np.array([180, 30, 200])),
            # ç»¿è‰²ï¼ˆè‰åœ°ï¼‰
            (np.array([35, 50, 50]), np.array([85, 255, 255])),
            # æ·±è“è‰²
            (np.array([110, 100, 50]), np.array([130, 255, 255])),
            # æµ…ç»¿è‰²
            (np.array([40, 30, 100]), np.array([80, 255, 255])),
        ]
        
        background_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)
        for lower, upper in color_ranges:
            mask = cv2.inRange(hsv, lower, upper)
            background_mask = cv2.bitwise_or(background_mask, mask)
        
        # åè½¬å¾—åˆ°å‰æ™¯
        foreground_mask = cv2.bitwise_not(background_mask)
        
        # å½¢æ€å­¦æ“ä½œæ”¹å–„æ©ç è´¨é‡
        kernel = np.ones((3, 3), np.uint8)
        foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, kernel)
        foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_OPEN, kernel)
        
        return foreground_mask
    
    def _create_edge_mask(self, image):
        """åˆ›å»ºè¾¹ç¼˜æ£€æµ‹æ©ç """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # ä½¿ç”¨Cannyè¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        
        # è†¨èƒ€è¾¹ç¼˜
        kernel = np.ones((3, 3), np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=1)
        
        # å¡«å……è¾¹ç¼˜å†…éƒ¨
        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
        
        return edges
    
    def _create_contour_mask(self, image):
        """åˆ›å»ºè½®å»“æ£€æµ‹æ©ç """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # é«˜æ–¯æ¨¡ç³Š
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # è‡ªé€‚åº”é˜ˆå€¼
        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # åˆ›å»ºæ©ç 
        mask = np.zeros(gray.shape, dtype=np.uint8)
        
        # è¿‡æ»¤å°è½®å»“ï¼Œä¿ç•™ä¸»è¦ç‰©ä½“
        min_area = (gray.shape[0] * gray.shape[1]) * 0.01  # æœ€å°é¢ç§¯é˜ˆå€¼
        for contour in contours:
            if cv2.contourArea(contour) > min_area:
                cv2.fillPoly(mask, [contour], 255)
        
        return mask
    
    def _create_grabcut_mask(self, image):
        """ä½¿ç”¨GrabCutç®—æ³•åˆ›å»ºæ©ç """
        try:
            # åˆ›å»ºæ©ç 
            mask = np.zeros(image.shape[:2], np.uint8)
            
            # åˆ›å»ºä¸´æ—¶æ•°ç»„
            bgdModel = np.zeros((1, 65), np.float64)
            fgdModel = np.zeros((1, 65), np.float64)
            
            # å®šä¹‰å‰æ™¯çŸ©å½¢ï¼ˆå›¾ç‰‡ä¸­å¿ƒåŒºåŸŸï¼‰
            h, w = image.shape[:2]
            rect = (w//4, h//4, w//2, h//2)
            
            # è¿è¡ŒGrabCut
            cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)
            
            # åˆ›å»ºæ©ç 
            mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
            
            return mask2 * 255
            
        except Exception as e:
            print(f"GrabCutå¤±è´¥: {e}")
            return None
    
    def _combine_masks(self, masks):
        """ç»„åˆå¤šä¸ªæ©ç  - ä¿®å¤ç‰ˆæœ¬"""
        if not masks or all(m is None for m in masks):
            return np.zeros((100, 100), dtype=np.uint8)
        
        # è¿‡æ»¤Noneå€¼
        valid_masks = [m for m in masks if m is not None]
        if not valid_masks:
            return np.zeros((100, 100), dtype=np.uint8)
        
        # ç¡®ä¿æ‰€æœ‰æ©ç å°ºå¯¸ä¸€è‡´
        target_shape = valid_masks[0].shape
        normalized_masks = []
        
        for mask in valid_masks:
            if mask.shape != target_shape:
                mask = cv2.resize(mask, target_shape[::-1])
            normalized_masks.append(mask)
        
        # ä½¿ç”¨é¢œè‰²æ©ç ä½œä¸ºåŸºç¡€ï¼ˆç¬¬ä¸€ä¸ªæ©ç ï¼‰
        if len(normalized_masks) > 0:
            base_mask = normalized_masks[0].copy()
            print(f"ä½¿ç”¨åŸºç¡€æ©ç ï¼Œéé›¶åƒç´ : {np.sum(base_mask > 0)}")
            
            # å¦‚æœæœ‰å…¶ä»–æ©ç ï¼Œå°è¯•æ”¹è¿›åŸºç¡€æ©ç 
            if len(normalized_masks) > 1:
                # ä½¿ç”¨è¾¹ç¼˜æ£€æµ‹æ©ç æ¥æ”¹è¿›è¾¹ç•Œ
                edge_mask = normalized_masks[1] if len(normalized_masks) > 1 else None
                if edge_mask is not None:
                    # åœ¨è¾¹ç¼˜åŒºåŸŸä½¿ç”¨è¾¹ç¼˜æ£€æµ‹ç»“æœ
                    edge_region = edge_mask > 0
                    base_mask[edge_region] = np.maximum(base_mask[edge_region], edge_mask[edge_region])
                    print(f"ç»“åˆè¾¹ç¼˜æ£€æµ‹åï¼Œéé›¶åƒç´ : {np.sum(base_mask > 0)}")
            
            return base_mask
        else:
            return np.zeros((100, 100), dtype=np.uint8)
    
    def _post_process_mask(self, mask):
        """åå¤„ç†æ©ç """
        # å½¢æ€å­¦æ“ä½œ
        kernel = np.ones((3, 3), np.uint8)
        
        # å¼€è¿ç®—å»é™¤å°å™ªç‚¹
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        # é—­è¿ç®—å¡«å……å°å­”
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        # é«˜æ–¯æ¨¡ç³Šè¾¹ç¼˜
        mask = cv2.GaussianBlur(mask, (3, 3), 0)
        
        return mask
    
    def _create_simple_color_mask(self, hsv):
        """åˆ›å»ºç®€å•çš„é¢œè‰²æ©ç ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        # è“è‰²å¤©ç©º
        lower_blue = np.array([100, 50, 50])
        upper_blue = np.array([130, 255, 255])
        blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)
        
        # ç™½è‰²äº‘æœµ
        lower_white = np.array([0, 0, 200])
        upper_white = np.array([180, 30, 255])
        white_mask = cv2.inRange(hsv, lower_white, upper_white)
        
        # åˆå¹¶æ©ç 
        background_mask = cv2.bitwise_or(blue_mask, white_mask)
        
        # åè½¬æ©ç å¾—åˆ°å‰æ™¯
        foreground_mask = cv2.bitwise_not(background_mask)
        
        # å½¢æ€å­¦æ“ä½œ
        kernel = np.ones((5, 5), np.uint8)
        foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, kernel)
        foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_OPEN, kernel)
        
        return foreground_mask
    
    def _apply_mask(self, image, mask):
        """åº”ç”¨æ©ç åˆ°å›¾ç‰‡"""
        try:
            # æ£€æŸ¥è¾“å…¥å‚æ•°
            if image is None:
                raise ValueError("è¾“å…¥å›¾ç‰‡ä¸ºç©º")
            if mask is None:
                raise ValueError("æ©ç ä¸ºç©º")
            
            # ç¡®ä¿å›¾ç‰‡æ˜¯3é€šé“RGB
            if len(image.shape) == 3 and image.shape[2] == 3:
                pass  # å·²ç»æ˜¯3é€šé“RGB
            elif len(image.shape) == 3 and image.shape[2] == 4:
                # å¦‚æœæ˜¯4é€šé“RGBAï¼Œè½¬æ¢ä¸ºRGB
                image = image[:, :, :3]
            elif len(image.shape) == 2:
                # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œè½¬æ¢ä¸ºRGB
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {image.shape}")
            
            # ç¡®ä¿æ©ç æ˜¯2D
            if len(mask.shape) == 3:
                mask = mask[:, :, 0]  # å–ç¬¬ä¸€ä¸ªé€šé“
            
            # åˆ›å»º4é€šé“RGBAå›¾ç‰‡
            result = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)
            
            # å¤åˆ¶RGBé€šé“
            result[:, :, :3] = image
            
            # è®¾ç½®Alphaé€šé“ - æ©ç å€¼ç›´æ¥ä½œä¸ºé€æ˜åº¦
            # æ©ç å€¼255è¡¨ç¤ºå®Œå…¨ä¸é€æ˜ï¼ˆå‰æ™¯ï¼‰ï¼Œ0è¡¨ç¤ºå®Œå…¨é€æ˜ï¼ˆèƒŒæ™¯ï¼‰
            result[:, :, 3] = mask
            
            print(f"æ©ç åº”ç”¨æˆåŠŸï¼Œç»“æœå›¾ç‰‡å°ºå¯¸: {result.shape}")
            print(f"Alphaé€šé“èŒƒå›´: {np.min(mask)} - {np.max(mask)}")
            
            return result
            
        except Exception as e:
            print(f"åº”ç”¨æ©ç å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def remove_background_sam(self, image_path, output_path=None, point_coords=None):
        """ä½¿ç”¨SAMæ¨¡å‹è¿›è¡ŒèƒŒæ™¯å»é™¤"""
        if not SAM_AVAILABLE:
            raise ImportError("SAM not available")
        
        try:
            # åˆå§‹åŒ–SAMæ¨¡å‹ï¼ˆè¿™é‡Œéœ€è¦ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼‰
            if self.sam_predictor is None:
                print("Initializing SAM model...")
                # è¿™é‡Œéœ€è¦è®¾ç½®æ¨¡å‹è·¯å¾„ï¼Œç”¨æˆ·éœ€è¦ä¸‹è½½SAMæ¨¡å‹
                sam_checkpoint = "sam_vit_h_4b8939.pth"  # éœ€è¦ç”¨æˆ·ä¸‹è½½
                model_type = "vit_h"
                
                if not os.path.exists(sam_checkpoint):
                    print(f"SAM model not found: {sam_checkpoint}")
                    print("Please download SAM model from: https://github.com/facebookresearch/segment-anything")
                    return None
                
                sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
                self.sam_predictor = SamPredictor(sam)
            
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError("Cannot read image")
            
            # è®¾ç½®å›¾ç‰‡
            self.sam_predictor.set_image(image)
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šç‚¹åæ ‡ï¼Œä½¿ç”¨å›¾ç‰‡ä¸­å¿ƒ
            if point_coords is None:
                h, w = image.shape[:2]
                point_coords = np.array([[w//2, h//2]])
            
            # é¢„æµ‹åˆ†å‰²
            masks, scores, logits = self.sam_predictor.predict(
                point_coords=point_coords,
                point_labels=np.array([1]),  # 1è¡¨ç¤ºå‰æ™¯
                multimask_output=True
            )
            
            # é€‰æ‹©æœ€ä½³æ©ç 
            best_mask_idx = np.argmax(scores)
            mask = masks[best_mask_idx]
            
            # åº”ç”¨æ©ç 
            result = self._apply_mask_sam(image, mask)
            
            # ä¿å­˜ç»“æœ
            if output_path:
                print(f"å‡†å¤‡ä¿å­˜ç»“æœï¼Œç»“æœå½¢çŠ¶: {result.shape}")
                
                # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰Alphaé€šé“
                if len(result.shape) == 3 and result.shape[2] == 4:
                    print(f"æ£€æµ‹åˆ°4é€šé“å›¾ç‰‡ï¼Œä½¿ç”¨PILä¿å­˜RGBA")
                    # æœ‰Alphaé€šé“ï¼Œä½¿ç”¨PILä¿å­˜ä»¥ä¿æŒé€æ˜åº¦
                    try:
                        pil_image = Image.fromarray(result, 'RGBA')
                        pil_image.save(output_path, 'PNG')
                        print(f"âœ“ ä½¿ç”¨PILä¿å­˜RGBAå›¾ç‰‡æˆåŠŸ: {output_path}")
                        print(f"ä¿å­˜çš„å›¾ç‰‡å°ºå¯¸: {result.shape}, Alphaé€šé“èŒƒå›´: {np.min(result[:, :, 3])} - {np.max(result[:, :, 3])}")
                    except Exception as e:
                        print(f"âŒ PILä¿å­˜å¤±è´¥: {e}")
                        # å¤‡ç”¨æ–¹æ³•ï¼šè½¬æ¢ä¸ºBGRä¿å­˜
                        result_bgr = cv2.cvtColor(result, cv2.COLOR_RGBA2BGR)
                        cv2.imwrite(output_path, result_bgr)
                        print(f"ä½¿ç”¨OpenCVå¤‡ç”¨ä¿å­˜")
                else:
                    print(f"æ£€æµ‹åˆ°{len(result.shape)}é€šé“å›¾ç‰‡ï¼Œä½¿ç”¨OpenCVä¿å­˜")
                    # æ²¡æœ‰Alphaé€šé“ï¼Œç›´æ¥ä¿å­˜
                    cv2.imwrite(output_path, result)
                
                return output_path
            else:
                return Image.fromarray(result)
                
        except Exception as e:
            print(f"SAM background removal failed: {e}")
            return None
    
    def _apply_mask_sam(self, image, mask):
        """ä½¿ç”¨SAMæ©ç åº”ç”¨åˆ†å‰²ç»“æœ"""
        # åˆ›å»º4é€šé“RGBAå›¾ç‰‡
        result = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)
        
        # å¤åˆ¶RGBé€šé“
        result[:, :, :3] = image
        
        # è®¾ç½®Alphaé€šé“
        result[:, :, 3] = mask.astype(np.uint8) * 255
        
        return result
    
    def remove_background(self, image_path, output_path=None, model_name=None, **kwargs):
        """ä¸»è¦çš„èƒŒæ™¯å»é™¤æ–¹æ³• - æ™ºèƒ½é€‰æ‹©æœ€ä½³æ¨¡å‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        if model_name:
            self.set_model(model_name)
        
        if not self.current_model:
            raise ValueError("No AI model available")
        
        print(f"ğŸ¯ ä½¿ç”¨ {self.current_model} æ¨¡å‹è¿›è¡ŒèƒŒæ™¯å»é™¤...")
        
        if self.current_model == 'rembg':
            print("ğŸš€ ä½¿ç”¨RemBGé«˜è´¨é‡AIæŠ å›¾...")
            result = self.remove_background_rembg(image_path, output_path)
            
            # æ™ºèƒ½è´¨é‡æ£€æµ‹å’Œå›é€€
            if result and output_path:
                quality_score = self._validate_rembg_quality(output_path)
                if quality_score < 60:  # è´¨é‡è¯„åˆ†ä½äº60åˆ†
                    print(f"âš  RemBGæŠ å›¾è´¨é‡è¾ƒä½ ({quality_score:.1f}/100)ï¼Œå°è¯•OpenCVå›é€€...")
                    
                    # å°è¯•OpenCVä½œä¸ºå›é€€æ–¹æ¡ˆ
                    try:
                        opencv_result = self.remove_background_opencv(image_path, output_path.replace('.png', '_opencv_fallback.png'))
                        if opencv_result:
                            opencv_quality = self._validate_opencv_quality(opencv_result)
                            print(f"ğŸ”„ OpenCVå›é€€å®Œæˆï¼Œè´¨é‡è¯„åˆ†: {opencv_quality:.1f}/100")
                            
                            # å¦‚æœOpenCVæ•ˆæœæ›´å¥½ï¼Œä½¿ç”¨OpenCVç»“æœ
                            if opencv_quality > quality_score:
                                print(f"âœ… OpenCVæ•ˆæœæ›´å¥½ï¼Œä½¿ç”¨OpenCVç»“æœ")
                                # æ›¿æ¢åŸæ–‡ä»¶
                                if os.path.exists(opencv_result):
                                    os.replace(opencv_result, output_path)
                                return output_path
                            else:
                                print(f"âœ… RemBGæ•ˆæœæ›´å¥½ï¼Œä¿ç•™RemBGç»“æœ")
                                # æ¸…ç†OpenCVå›é€€æ–‡ä»¶
                                if os.path.exists(opencv_result):
                                    os.remove(opencv_result)
                    except Exception as e:
                        print(f"âš  OpenCVå›é€€å¤±è´¥: {e}")
            
            return result
            
        elif self.current_model == 'opencv':
            print("ğŸ”§ ä½¿ç”¨OpenCVåŸºç¡€å›¾åƒå¤„ç†...")
            return self.remove_background_opencv(image_path, output_path)
        elif self.current_model == 'sam':
            print("ğŸ§  ä½¿ç”¨SAMå…ˆè¿›åˆ†å‰²æ¨¡å‹...")
            return self.remove_background_sam(image_path, output_path, **kwargs)
        else:
            raise ValueError(f"Unknown model: {self.current_model}")
    
    def _validate_opencv_quality(self, output_path):
        """éªŒè¯OpenCVæŠ å›¾è´¨é‡"""
        try:
            # è¯»å–å¤„ç†åçš„å›¾ç‰‡
            processed = cv2.imread(output_path, cv2.IMREAD_UNCHANGED)
            if processed is None:
                return 0
            
            if len(processed.shape) == 3 and processed.shape[2] == 4:
                alpha = processed[:, :, 3]
                
                # è®¡ç®—è´¨é‡æŒ‡æ ‡
                foreground_ratio = np.sum(alpha > 128) / alpha.size * 100
                
                # å‰æ™¯åŒºåŸŸè¯„åˆ†ï¼ˆ40-80%ä¸ºç†æƒ³èŒƒå›´ï¼ŒOpenCVé€šå¸¸æ›´ä¿å®ˆï¼‰
                if 40 <= foreground_ratio <= 80:
                    foreground_score = 100
                elif foreground_ratio < 40:
                    foreground_score = max(0, 100 - (40 - foreground_ratio) * 2)
                else:
                    foreground_score = max(0, 100 - (foreground_ratio - 80) * 1.5)
                
                # è¾¹ç¼˜è´¨é‡è¯„åˆ†
                edge_quality = self._analyze_edge_quality(alpha)
                edge_score = edge_quality * 20  # è½¬æ¢ä¸º0-100åˆ†
                
                # ç»¼åˆè¯„åˆ†
                total_score = (foreground_score * 0.6 + edge_score * 0.4)
                
                return total_score
            
            return 0
            
        except Exception as e:
            print(f"âš  OpenCVè´¨é‡éªŒè¯å¤±è´¥: {e}")
            return 0
    
    def remove_background_pygame_surface(self, pygame_surface, output_path=None, model_name=None):
        """ä»Pygame surfaceå»é™¤èƒŒæ™¯"""
        # å°†Pygame surfaceè½¬æ¢ä¸ºPIL Image
        pil_image = self._pygame_to_pil(pygame_surface)
        
        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_path = "temp_image.png"
        pil_image.save(temp_path)
        
        try:
            # å»é™¤èƒŒæ™¯
            result = self.remove_background(temp_path, output_path, model_name)
            return result
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.remove(temp_path)
    
    def _pygame_to_pil(self, pygame_surface):
        """å°†Pygame surfaceè½¬æ¢ä¸ºPIL Image"""
        # è·å–surfaceæ•°æ®
        string_image = pygame.image.tostring(pygame_surface, "RGBA", False)
        
        # åˆ›å»ºPIL Image
        pil_image = Image.frombytes("RGBA", pygame_surface.get_size(), string_image)
        
        return pil_image
    
    def _pil_to_pygame(self, pil_image):
        """å°†PIL Imageè½¬æ¢ä¸ºPygame surface"""
        # è½¬æ¢ä¸ºRGBAæ¨¡å¼
        if pil_image.mode != 'RGBA':
            pil_image = pil_image.convert('RGBA')
        
        # è½¬æ¢ä¸ºPygame surface
        mode = pil_image.mode
        size = pil_image.size
        data = pil_image.tobytes()
        
        pygame_surface = pygame.image.fromstring(data, size, mode)
        
        return pygame_surface
    
    def auto_detect_airplane(self, image_path):
        """è‡ªåŠ¨æ£€æµ‹å›¾ç‰‡ä¸­çš„é£æœº"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„é£æœºæ£€æµ‹é€»è¾‘
        # ç›®å‰è¿”å›å›¾ç‰‡ä¸­å¿ƒç‚¹ä½œä¸ºé»˜è®¤å€¼
        try:
            image = cv2.imread(image_path)
            if image is not None:
                h, w = image.shape[:2]
                return np.array([[w//2, h//2]])
        except:
            pass
        
        return None

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºèƒŒæ™¯å»é™¤å™¨
    remover = BackgroundRemover()
    
    # æ£€æŸ¥å¯ç”¨æ¨¡å‹
    print("Available models:", remover.get_available_models())
    
    # æµ‹è¯•èƒŒæ™¯å»é™¤
    test_image = "test_airplane.png"
    if os.path.exists(test_image):
        print(f"Testing background removal on {test_image}")
        
        # ä½¿ç”¨é»˜è®¤æ¨¡å‹
        result = remover.remove_background(test_image)
        if result:
            print("Background removal successful!")
            if isinstance(result, str):
                print(f"Result saved to: {result}")
            else:
                print("Result returned as PIL Image")
        else:
            print("Background removal failed")
    else:
        print(f"Test image {test_image} not found")
