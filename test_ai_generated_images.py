#!/usr/bin/env python3
"""
æµ‹è¯•AIç”Ÿæˆå›¾ç‰‡çš„æŠ å›¾æ•ˆæœ
"""

import os
import cv2
import numpy as np
from PIL import Image
import time

def test_ai_generated_images():
    """æµ‹è¯•AIç”Ÿæˆå›¾ç‰‡çš„æŠ å›¾æ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯•AIç”Ÿæˆå›¾ç‰‡çš„æŠ å›¾æ•ˆæœ...")
    
    try:
        from background_remover import BackgroundRemover
        
        # åˆ›å»ºèƒŒæ™¯å»é™¤å™¨
        remover = BackgroundRemover()
        print(f"âœ“ èƒŒæ™¯å»é™¤å™¨åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {remover.get_available_models()}")
        
        # æŸ¥æ‰¾AIç”Ÿæˆçš„å›¾ç‰‡æˆ–ç±»ä¼¼çš„å¤æ‚å›¾ç‰‡
        test_images = []
        for root, dirs, files in os.walk('.'):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    # ä¼˜å…ˆé€‰æ‹©å¯èƒ½æ›´å¤æ‚çš„å›¾ç‰‡
                    if not file.startswith('.') and 'test' not in file.lower() and 'debug' not in file.lower():
                        test_images.append(os.path.join(root, file))
                        if len(test_images) >= 5:
                            break
            if len(test_images) >= 5:
                break
        
        if not test_images:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
            return False
        
        print(f"âœ“ æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡: {len(test_images)} å¼ ")
        
        # æµ‹è¯•æ¯å¼ å›¾ç‰‡
        for i, test_image in enumerate(test_images[:3]):  # æµ‹è¯•å‰3å¼ 
            print(f"\nğŸ” æµ‹è¯•å›¾ç‰‡ {i+1}: {test_image}")
            
            # åˆ†æåŸå§‹å›¾ç‰‡
            analyze_original_image(test_image)
            
            # æµ‹è¯•ä¸åŒæ¨¡å‹çš„æŠ å›¾æ•ˆæœ
            test_different_models(remover, test_image, i)
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def analyze_original_image(image_path):
    """åˆ†æåŸå§‹å›¾ç‰‡"""
    try:
        # è¯»å–å›¾ç‰‡
        image = cv2.imread(image_path)
        if image is None:
            print("âŒ æ— æ³•è¯»å–å›¾ç‰‡")
            return
        
        # åŸºæœ¬ä¿¡æ¯
        height, width = image.shape[:2]
        channels = image.shape[2] if len(image.shape) > 2 else 1
        file_size = os.path.getsize(image_path)
        
        print(f"ğŸ“Š åŸå§‹å›¾ç‰‡ä¿¡æ¯:")
        print(f"  å°ºå¯¸: {width} x {height}")
        print(f"  é€šé“: {channels}")
        print(f"  æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        # é¢œè‰²åˆ†æ
        if channels == 3:
            # è½¬æ¢ä¸ºRGBè¿›è¡Œåˆ†æ
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # è®¡ç®—ä¸»è¦é¢œè‰²
            colors = ['çº¢è‰²', 'ç»¿è‰²', 'è“è‰²']
            for i, color in enumerate(colors):
                channel = image_rgb[:, :, i]
                avg_value = np.mean(channel)
                std_value = np.std(channel)
                print(f"  {color}é€šé“: å¹³å‡å€¼={avg_value:.1f}, æ ‡å‡†å·®={std_value:.1f}")
            
            # è®¡ç®—æ•´ä½“è‰²å½©ä¸°å¯Œåº¦
            color_variance = np.var(image_rgb, axis=(0, 1))
            total_variance = np.sum(color_variance)
            print(f"  è‰²å½©ä¸°å¯Œåº¦: {total_variance:.1f}")
            
            # æ£€æµ‹æ˜¯å¦ä¸ºAIç”Ÿæˆå›¾ç‰‡çš„ç‰¹å¾
            detect_ai_generated_features(image_rgb)
        
    except Exception as e:
        print(f"âŒ åˆ†æåŸå§‹å›¾ç‰‡å¤±è´¥: {e}")

def detect_ai_generated_features(image_rgb):
    """æ£€æµ‹AIç”Ÿæˆå›¾ç‰‡çš„ç‰¹å¾"""
    try:
        # æ£€æµ‹è‰²å½©è¿‡æ¸¡çš„å¹³æ»‘æ€§
        # AIç”Ÿæˆçš„å›¾ç‰‡é€šå¸¸æœ‰æ›´å¹³æ»‘çš„è‰²å½©è¿‡æ¸¡
        
        # è®¡ç®—ç›¸é‚»åƒç´ çš„å·®å¼‚
        diff_x = np.diff(image_rgb, axis=1)
        diff_y = np.diff(image_rgb, axis=0)
        
        # è®¡ç®—å¹³å‡å·®å¼‚
        avg_diff_x = np.mean(np.abs(diff_x))
        avg_diff_y = np.mean(np.abs(diff_y))
        
        print(f"  è‰²å½©è¿‡æ¸¡åˆ†æ:")
        print(f"    æ°´å¹³æ–¹å‘å¹³å‡å·®å¼‚: {avg_diff_x:.1f}")
        print(f"    å‚ç›´æ–¹å‘å¹³å‡å·®å¼‚: {avg_diff_y:.1f}")
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºAIç”Ÿæˆå›¾ç‰‡
        if avg_diff_x < 15 and avg_diff_y < 15:
            print(f"    ğŸ¨ å¯èƒ½æ˜¯AIç”Ÿæˆçš„å›¾ç‰‡ (è‰²å½©è¿‡æ¸¡å¹³æ»‘)")
        else:
            print(f"    ğŸ“· å¯èƒ½æ˜¯çœŸå®æ‹æ‘„çš„å›¾ç‰‡ (è‰²å½©è¿‡æ¸¡æ˜æ˜¾)")
            
    except Exception as e:
        print(f"    âŒ AIç‰¹å¾æ£€æµ‹å¤±è´¥: {e}")

def test_different_models(remover, test_image, index):
    """æµ‹è¯•ä¸åŒæ¨¡å‹çš„æŠ å›¾æ•ˆæœ"""
    print(f"\nğŸ”¬ æµ‹è¯•ä¸åŒæ¨¡å‹çš„æŠ å›¾æ•ˆæœ...")
    
    models_to_test = ['rembg', 'opencv']
    available_models = remover.get_available_models()
    
    for model in models_to_test:
        if model in available_models:
            print(f"\nğŸ¯ æµ‹è¯•æ¨¡å‹: {model}")
            
            # è®¾ç½®æ¨¡å‹
            remover.set_model(model)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_path = f"test_{model}_{index+1}_{os.path.basename(test_image)}"
            
            try:
                start_time = time.time()
                
                # å»é™¤èƒŒæ™¯
                result = remover.remove_background(test_image, output_path)
                
                if result:
                    processing_time = time.time() - start_time
                    print(f"  âœ… æŠ å›¾æˆåŠŸï¼è€—æ—¶: {processing_time:.2f}ç§’")
                    
                    # åˆ†æç»“æœ
                    analyze_result_quality(test_image, output_path, model)
                    
                    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                    try:
                        os.remove(output_path)
                        print("  âœ“ æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
                    except:
                        pass
                        
                else:
                    print(f"  âŒ æŠ å›¾å¤±è´¥")
                    
            except Exception as e:
                print(f"  âŒ æŠ å›¾è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        else:
            print(f"âš  æ¨¡å‹ {model} ä¸å¯ç”¨")

def analyze_result_quality(original_path, processed_path, model_name):
    """åˆ†ææŠ å›¾ç»“æœçš„è´¨é‡"""
    try:
        print(f"  ğŸ” ç»“æœè´¨é‡åˆ†æ:")
        
        # è¯»å–åŸå§‹å›¾ç‰‡
        original = cv2.imread(original_path)
        if original is None:
            print("    âŒ æ— æ³•è¯»å–åŸå§‹å›¾ç‰‡")
            return
        
        # è¯»å–å¤„ç†åçš„å›¾ç‰‡
        processed = cv2.imread(processed_path, cv2.IMREAD_UNCHANGED)
        if processed is None:
            print("    âŒ æ— æ³•è¯»å–å¤„ç†åçš„å›¾ç‰‡")
            return
        
        # åŸºæœ¬ä¿¡æ¯å¯¹æ¯”
        original_size = original.shape[:2]
        processed_size = processed.shape[:2]
        file_size = os.path.getsize(processed_path)
        
        print(f"    å¤„ç†åæ–‡ä»¶å¤§å°: {file_size} bytes")
        
        # æ£€æŸ¥é€æ˜é€šé“
        if len(processed.shape) == 3 and processed.shape[2] == 4:
            print(f"    âœ… æˆåŠŸç”ŸæˆRGBAé€æ˜å›¾ç‰‡")
            
            # æå–Alphaé€šé“
            alpha = processed[:, :, 3]
            
            # è®¡ç®—é€æ˜åŒºåŸŸæ¯”ä¾‹
            transparent_pixels = np.sum(alpha < 128)
            total_pixels = alpha.shape[0] * alpha.shape[1]
            transparent_ratio = transparent_pixels / total_pixels * 100
            
            print(f"    é€æ˜åŒºåŸŸæ¯”ä¾‹: {transparent_ratio:.1f}%")
            
            # åˆ†æå‰æ™¯åŒºåŸŸ
            foreground_pixels = np.sum(alpha > 128)
            foreground_ratio = foreground_pixels / total_pixels * 100
            print(f"    å‰æ™¯åŒºåŸŸæ¯”ä¾‹: {foreground_ratio:.1f}%")
            
            # åˆ†æè‰²å½©ä¿ç•™æƒ…å†µ
            analyze_color_preservation(original, processed, alpha, model_name)
            
        else:
            print(f"    âš  å¤„ç†åå›¾ç‰‡æ²¡æœ‰é€æ˜é€šé“")
            
    except Exception as e:
        print(f"    âŒ ç»“æœè´¨é‡åˆ†æå¤±è´¥: {e}")

def analyze_color_preservation(original, processed, alpha, model_name):
    """åˆ†æè‰²å½©ä¿ç•™æƒ…å†µ"""
    try:
        print(f"    ğŸ¨ è‰²å½©ä¿ç•™åˆ†æ:")
        
        # åˆ›å»ºå‰æ™¯æ©ç 
        foreground_mask = alpha > 128
        
        if np.sum(foreground_mask) == 0:
            print(f"      âŒ æ²¡æœ‰å‰æ™¯åŒºåŸŸ")
            return
        
        # åˆ†æå‰æ™¯åŒºåŸŸçš„è‰²å½©
        if len(original.shape) == 3 and len(processed.shape) == 4:
            # åŸå§‹å›¾ç‰‡çš„å‰æ™¯åŒºåŸŸ
            original_foreground = original[foreground_mask]
            processed_foreground = processed[foreground_mask, :3]  # åªå–RGBé€šé“
            
            # è®¡ç®—è‰²å½©ç»Ÿè®¡
            original_mean = np.mean(original_foreground, axis=0)
            processed_mean = np.mean(processed_foreground, axis=0)
            
            # è®¡ç®—è‰²å½©å·®å¼‚
            color_diff = np.abs(original_mean - processed_mean)
            total_color_diff = np.sum(color_diff)
            
            print(f"      åŸå§‹å‰æ™¯å¹³å‡è‰²å½©: R={original_mean[2]:.1f}, G={original_mean[1]:.1f}, B={original_mean[0]:.1f}")
            print(f"      å¤„ç†åå‰æ™¯å¹³å‡è‰²å½©: R={processed_mean[2]:.1f}, G={processed_mean[1]:.1f}, B={processed_mean[0]:.1f}")
            print(f"      è‰²å½©å·®å¼‚: {total_color_diff:.1f}")
            
            # è¯„ä¼°è‰²å½©ä¿ç•™è´¨é‡
            if total_color_diff < 10:
                print(f"      âœ… è‰²å½©ä¿ç•™ä¼˜ç§€")
            elif total_color_diff < 30:
                print(f"      âš  è‰²å½©ä¿ç•™ä¸€èˆ¬")
            else:
                print(f"      âŒ è‰²å½©ä¸¢å¤±ä¸¥é‡")
            
            # æ¨¡å‹ç‰¹å®šçš„åˆ†æ
            if model_name == 'rembg':
                analyze_rembg_specific_issues(original, processed, alpha)
            elif model_name == 'opencv':
                analyze_opencv_specific_issues(original, processed, alpha)
                
    except Exception as e:
        print(f"      âŒ è‰²å½©ä¿ç•™åˆ†æå¤±è´¥: {e}")

def analyze_rembg_specific_issues(original, processed, alpha):
    """åˆ†æRemBGç‰¹å®šçš„é—®é¢˜"""
    try:
        print(f"      ğŸ” RemBGç‰¹å®šåˆ†æ:")
        
        # æ£€æµ‹è¾¹ç¼˜è¿‡åº¦æŠ å›¾é—®é¢˜
        # ä½¿ç”¨å½¢æ€å­¦æ“ä½œæ£€æµ‹è¾¹ç¼˜
        kernel = np.ones((3, 3), np.uint8)
        edge_mask = cv2.morphologyEx(alpha, cv2.MORPH_GRADIENT, kernel)
        
        # è®¡ç®—è¾¹ç¼˜åŒºåŸŸçš„è‰²å½©å˜åŒ–
        edge_pixels = edge_mask > 0
        if np.sum(edge_pixels) > 0:
            edge_original = original[edge_pixels]
            edge_processed = processed[edge_pixels, :3]
            
            edge_color_diff = np.mean(np.abs(edge_original - edge_processed))
            print(f"        è¾¹ç¼˜åŒºåŸŸè‰²å½©å·®å¼‚: {edge_color_diff:.1f}")
            
            if edge_color_diff > 50:
                print(f"        âš  è¾¹ç¼˜åŒºåŸŸå¯èƒ½å­˜åœ¨è¿‡åº¦æŠ å›¾")
        
        # æ£€æµ‹å‰æ™¯åŒºåŸŸæ˜¯å¦è¿‡å°
        foreground_ratio = np.sum(alpha > 128) / alpha.size * 100
        if foreground_ratio < 20:
            print(f"        âš  å‰æ™¯åŒºåŸŸè¿‡å°ï¼Œå¯èƒ½å­˜åœ¨è¿‡åº¦æŠ å›¾")
        elif foreground_ratio > 80:
            print(f"        âš  å‰æ™¯åŒºåŸŸè¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨æŠ å›¾ä¸è¶³")
        else:
            print(f"        âœ… å‰æ™¯åŒºåŸŸæ¯”ä¾‹åˆç†")
            
    except Exception as e:
        print(f"        âŒ RemBGç‰¹å®šåˆ†æå¤±è´¥: {e}")

def analyze_opencv_specific_issues(original, processed, alpha):
    """åˆ†æOpenCVç‰¹å®šçš„é—®é¢˜"""
    try:
        print(f"      ğŸ” OpenCVç‰¹å®šåˆ†æ:")
        
        # æ£€æµ‹é¢œè‰²é˜ˆå€¼é—®é¢˜
        # OpenCVå¯èƒ½å› ä¸ºé¢œè‰²é˜ˆå€¼è®¾ç½®ä¸å½“å¯¼è‡´é—®é¢˜
        
        # æ£€æŸ¥æ©ç çš„è¿ç»­æ€§
        kernel = np.ones((3, 3), np.uint8)
        closed_mask = cv2.morphologyEx(alpha, cv2.MORPH_CLOSE, kernel)
        
        # è®¡ç®—æ©ç çš„è¿ç»­æ€§
        continuity_score = np.sum(closed_mask == alpha) / alpha.size * 100
        print(f"        æ©ç è¿ç»­æ€§: {continuity_score:.1f}%")
        
        if continuity_score < 90:
            print(f"        âš  æ©ç å¯èƒ½å­˜åœ¨æ–­è£‚æˆ–ä¸è¿ç»­")
        
        # æ£€æŸ¥è¾¹ç¼˜è´¨é‡
        edge_quality = analyze_edge_quality(alpha)
        print(f"        è¾¹ç¼˜è´¨é‡: {edge_quality}")
        
    except Exception as e:
        print(f"        âŒ OpenCVç‰¹å®šåˆ†æå¤±è´¥: {e}")

def analyze_edge_quality(alpha_mask):
    """åˆ†æè¾¹ç¼˜è´¨é‡"""
    try:
        # ä½¿ç”¨Sobelç®—å­æ£€æµ‹è¾¹ç¼˜
        sobel_x = cv2.Sobel(alpha_mask, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(alpha_mask, cv2.CV_64F, 0, 1, ksize=3)
        
        # è®¡ç®—è¾¹ç¼˜å¼ºåº¦
        edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        
        # è®¡ç®—å¹³å‡è¾¹ç¼˜å¼ºåº¦
        avg_edge_strength = np.mean(edge_magnitude)
        
        if avg_edge_strength < 10:
            return "æ¨¡ç³Š"
        elif avg_edge_strength < 30:
            return "ä¸€èˆ¬"
        elif avg_edge_strength < 60:
            return "æ¸…æ™°"
        else:
            return "éå¸¸æ¸…æ™°"
            
    except Exception as e:
        return f"åˆ†æå¤±è´¥: {e}"

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("AIç”Ÿæˆå›¾ç‰‡æŠ å›¾æ•ˆæœæµ‹è¯•")
    print("=" * 50)
    
    success = test_ai_generated_images()
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ’¡ é—®é¢˜åˆ†æ:")
        print("â€¢ å¦‚æœRemBGæŠ å›¾åè‰²å½©ä¸¢å¤±ä¸¥é‡ï¼Œè¯´æ˜å­˜åœ¨è¿‡åº¦æŠ å›¾é—®é¢˜")
        print("â€¢ å¦‚æœå‰æ™¯åŒºåŸŸè¿‡å°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æŠ å›¾å‚æ•°")
        print("â€¢ å¦‚æœè¾¹ç¼˜è´¨é‡å·®ï¼Œå¯èƒ½éœ€è¦åå¤„ç†ä¼˜åŒ–")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    print("=" * 50)

if __name__ == "__main__":
    main()
